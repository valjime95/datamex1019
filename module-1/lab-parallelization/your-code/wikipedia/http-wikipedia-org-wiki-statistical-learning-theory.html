b'<!DOCTYPE html>\n<html class="client-nojs" lang="en" dir="ltr">\n<head>\n<meta charset="UTF-8"/>\n<title>Statistical learning theory - Wikipedia</title>\n<script>document.documentElement.className="client-js";RLCONF={"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Statistical_learning_theory","wgTitle":"Statistical learning theory","wgCurRevisionId":915171435,"wgRevisionId":915171435,"wgArticleId":1053303,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Machine learning","Estimation theory"],"wgBreakFrames":!1,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Statistical_learning_theory","wgRelevantArticleId":1053303,"wgRequestId":"XcH0KQpAMF0AABqu6tMAAABC","wgCSPNonce":!1,\n"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q7604400","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready",\n"mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP",\n"ext.centralNotice.startUp","skins.vector.js"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\\\","watchToken":"+\\\\","csrfToken":"+\\\\"});\n});});</script>\n<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>\n<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>\n<meta name="ResourceLoaderDynamicStyles" content=""/>\n<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>\n<meta name="generator" content="MediaWiki 1.35.0-wmf.4"/>\n<meta name="referrer" content="origin"/>\n<meta name="referrer" content="origin-when-crossorigin"/>\n<meta name="referrer" content="origin-when-cross-origin"/>\n<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/1200px-Kernel_Machine.svg.png"/>\n<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Statistical_learning_theory"/>\n<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Statistical_learning_theory&amp;action=edit"/>\n<link rel="edit" title="Edit this page" href="/w/index.php?title=Statistical_learning_theory&amp;action=edit"/>\n<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>\n<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>\n<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>\n<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>\n<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>\n<link rel="canonical" href="https://en.wikipedia.org/wiki/Statistical_learning_theory"/>\n<link rel="dns-prefetch" href="//login.wikimedia.org"/>\n<link rel="dns-prefetch" href="//meta.wikimedia.org" />\n<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->\n</head>\n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Statistical_learning_theory rootpage-Statistical_learning_theory skin-vector action-view">\n<div id="mw-page-base" class="noprint"></div>\n<div id="mw-head-base" class="noprint"></div>\n<div id="content" class="mw-body" role="main">\n\t<a id="top"></a>\n\t<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>\n\t<div class="mw-indicators mw-body-content">\n</div>\n\n\t<h1 id="firstHeading" class="firstHeading" lang="en">Statistical learning theory</h1>\n\t\n\t<div id="bodyContent" class="mw-body-content">\n\t\t<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>\n\t\t<div id="contentSub"></div>\n\t\t\n\t\t\n\t\t\n\t\t<div id="jump-to-nav"></div>\n\t\t<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>\n\t\t<a class="mw-jump-link" href="#p-search">Jump to search</a>\n\t\t<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></div>\n<div role="note" class="hatnote navigation-not-searchable">This article is about statistical learning in machine learning. For its use in psychology, see <a href="/wiki/Statistical_learning_in_language_acquisition" title="Statistical learning in language acquisition">Statistical learning in language acquisition</a>.</div>\n<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br /><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a href="/wiki/File:Kernel_Machine.svg" class="image"><img alt="Kernel Machine.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" decoding="async" width="220" height="100" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" data-file-width="512" data-file-height="233" /></a></td></tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>\n<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>\n<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>\n<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>\n<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>\n<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>\n<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>\n<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>\n<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>\n<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>\n<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>\n<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>\n<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>\n<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>\n<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br /><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>&#160;&#8226;&#32;<b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>\n<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>\n<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>\n<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>\n<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>\n<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>\n<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>\n<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>\n<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>\n<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>\n<li><a href="/wiki/CURE_data_clustering_algorithm" class="mw-redirect" title="CURE data clustering algorithm">CURE</a></li>\n<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>\n<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>\n<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation\xe2\x80\x93maximization algorithm">Expectation\xe2\x80\x93maximization (EM)</a></li>\n<li><br /><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>\n<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>\n<li><a href="/wiki/Mean-shift" class="mw-redirect" title="Mean-shift">Mean-shift</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>\n<li><a href="/wiki/Canonical_correlation_analysis" class="mw-redirect" title="Canonical correlation analysis">CCA</a></li>\n<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>\n<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>\n<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>\n<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>\n<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>\n<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/K-nearest_neighbors_classification" class="mw-redirect" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_networks" class="mw-redirect" title="Artificial neural networks">Artificial neural networks</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>\n<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>\n<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>\n<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>\n<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>\n<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>\n<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>\n<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>\n<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>\n<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>\n<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>\n<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>\n<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State\xe2\x80\x93action\xe2\x80\x93reward\xe2\x80\x93state\xe2\x80\x93action">SARSA</a></li>\n<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Bias%E2%80%93variance_dilemma" class="mw-redirect" title="Bias\xe2\x80\x93variance dilemma">Bias\xe2\x80\x93variance dilemma</a></li>\n<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>\n<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>\n<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>\n<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>\n<li><a class="mw-selflink selflink">Statistical learning</a></li>\n<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik\xe2\x80\x93Chervonenkis theory">VC theory</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NIPS</a></li>\n<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>\n<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>\n<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>\n<li><a rel="nofollow" class="external text" href="https://arxiv.org/list/cs.LG/recent">ArXiv:cs.LG</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>\n<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>\n<p><b>Statistical learning theory</b> is a framework for <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a>\ndrawing from the fields of <a href="/wiki/Statistics" title="Statistics">statistics</a> and <a href="/wiki/Functional_analysis" title="Functional analysis">functional analysis</a>.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup><sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup> Statistical learning theory deals with the problem of finding a predictive function based on data. Statistical learning theory has led to successful applications in fields such as <a href="/wiki/Computer_vision" title="Computer vision">computer vision</a>, <a href="/wiki/Speech_recognition" title="Speech recognition">speech recognition</a>, <a href="/wiki/Bioinformatics" title="Bioinformatics">bioinformatics</a> and <a href="/wiki/Baseball" title="Baseball">baseball</a>.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup>\n</p>\n<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>\n<ul>\n<li class="toclevel-1 tocsection-1"><a href="#Introduction"><span class="tocnumber">1</span> <span class="toctext">Introduction</span></a></li>\n<li class="toclevel-1 tocsection-2"><a href="#Formal_description"><span class="tocnumber">2</span> <span class="toctext">Formal description</span></a></li>\n<li class="toclevel-1 tocsection-3"><a href="#Loss_functions"><span class="tocnumber">3</span> <span class="toctext">Loss functions</span></a>\n<ul>\n<li class="toclevel-2 tocsection-4"><a href="#Regression"><span class="tocnumber">3.1</span> <span class="toctext">Regression</span></a></li>\n<li class="toclevel-2 tocsection-5"><a href="#Classification"><span class="tocnumber">3.2</span> <span class="toctext">Classification</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-6"><a href="#Regularization"><span class="tocnumber">4</span> <span class="toctext">Regularization</span></a></li>\n<li class="toclevel-1 tocsection-7"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li>\n<li class="toclevel-1 tocsection-8"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>\n</ul>\n</div>\n\n<h2><span class="mw-headline" id="Introduction">Introduction</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=1" title="Edit section: Introduction">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The goals of learning are understanding and prediction. Learning falls into many categories, including <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a>, <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised learning</a>, <a href="/wiki/Online_machine_learning" title="Online machine learning">online learning</a>, and <a href="/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a>. From the perspective of statistical learning theory, supervised learning is best understood.<sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup> Supervised learning involves learning from a <a href="/wiki/Training_set" class="mw-redirect" title="Training set">training set</a> of data. Every point in the training is an input-output pair, where the input maps to an output. The learning problem consists of inferring the function that maps between the input and the output, such that the learned function can be used to predict the output from future input.\n</p><p>Depending on the type of output, supervised learning problems are either problems of <a href="/wiki/Regression_analysis" title="Regression analysis">regression</a> or problems of <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a>. If the output takes a continuous range of values, it is a regression problem. Using <a href="/wiki/Ohm%27s_Law" class="mw-redirect" title="Ohm&#39;s Law">Ohm\'s Law</a> as an example, a regression could be performed with voltage as input and current as an output. The regression would find the functional relationship between voltage and current to be <span class="nowrap"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle R}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>R</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle R}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4b0bfb3769bf24d80e15374dc37b0441e2616e33" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.764ex; height:2.176ex;" alt="R"/></span></span>, such that\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle U=RI}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>U</mi>\n        <mo>=</mo>\n        <mi>R</mi>\n        <mi>I</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle U=RI}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/874de41d32da504544078c0e81b73273c1886c7c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:7.817ex; height:2.176ex;" alt="{\\displaystyle U=RI}"/></span></dd></dl>\n<p>Classification problems are those for which the output will be an element from a discrete set of labels. Classification is very common for machine learning applications. In <a href="/wiki/Facial_recognition_system" title="Facial recognition system">facial recognition</a>, for instance, a picture of a person\'s face would be the input, and the output label would be that person\'s name. The input would be represented by a large multidimensional vector whose elements represent pixels in the picture.\n</p><p>After learning a function based on the training set data, that function is validated on a test set of data, data that did not appear in the training set.\n</p>\n<h2><span class="mw-headline" id="Formal_description">Formal description</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=2" title="Edit section: Formal description">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>Take <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle X}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>X</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"/></span> to be the <a href="/wiki/Vector_space" title="Vector space">vector space</a> of all possible inputs, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle Y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>Y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle Y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"/></span> to be\nthe vector space of all possible outputs. Statistical learning theory takes the perspective that there is some unknown <a href="/wiki/Probability_distribution" title="Probability distribution">probability distribution</a> over the product space <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle Z=X\\times Y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>Z</mi>\n        <mo>=</mo>\n        <mi>X</mi>\n        <mo>&#x00D7;<!-- \xc3\x97 --></mo>\n        <mi>Y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle Z=X\\times Y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c8af2c76ff03cd3f68caf3caeb6792ee1f7f0898" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:11.373ex; height:2.176ex;" alt="Z = X \\times Y"/></span>, i.e. there exists some unknown <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p(z)=p({\\vec {x}},y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>z</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p(z)=p({\\vec {x}},y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f39df3dba644c278439cea9c931fb328ab202014" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:13.753ex; height:2.843ex;" alt="p(z)=p({\\vec  {x}},y)"/></span>. The training set is made up of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle n}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>n</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle n}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;" alt="n"/></span> samples from this probability distribution, and is notated \n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle S=\\{({\\vec {x}}_{1},y_{1}),\\dots ,({\\vec {x}}_{n},y_{n})\\}=\\{{\\vec {z}}_{1},\\dots ,{\\vec {z}}_{n}\\}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>S</mi>\n        <mo>=</mo>\n        <mo fence="false" stretchy="false">{</mo>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mover>\n                <mi>x</mi>\n                <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n              </mover>\n            </mrow>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mover>\n                <mi>x</mi>\n                <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n              </mover>\n            </mrow>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo fence="false" stretchy="false">}</mo>\n        <mo>=</mo>\n        <mo fence="false" stretchy="false">{</mo>\n        <msub>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mover>\n                <mi>z</mi>\n                <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n              </mover>\n            </mrow>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mover>\n                <mi>z</mi>\n                <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n              </mover>\n            </mrow>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>n</mi>\n          </mrow>\n        </msub>\n        <mo fence="false" stretchy="false">}</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle S=\\{({\\vec {x}}_{1},y_{1}),\\dots ,({\\vec {x}}_{n},y_{n})\\}=\\{{\\vec {z}}_{1},\\dots ,{\\vec {z}}_{n}\\}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/96193cc7296413d9547ecf9226fef229147553fd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:42.6ex; height:2.843ex;" alt="S=\\{({\\vec  {x}}_{1},y_{1}),\\dots ,({\\vec  {x}}_{n},y_{n})\\}=\\{{\\vec  {z}}_{1},\\dots ,{\\vec  {z}}_{n}\\}"/></span></dd></dl>\n<p>Every <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\vec {x}}_{i}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mover>\n                <mi>x</mi>\n                <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n              </mover>\n            </mrow>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\vec {x}}_{i}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/97dc64e456d28b08c449ec343111cc5c3ce39f72" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.676ex;" alt="{\\vec {x}}_{i}"/></span> is an input vector from the training data, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y_{i}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y_{i}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/67d30d30b6c2dbe4d6f150d699de040937ecc95f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.939ex; height:2.009ex;" alt="y_{i}"/></span>\nis the output that corresponds to it.\n</p><p>In this formalism, the inference problem consists of finding a function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f:X\\to Y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo>:</mo>\n        <mi>X</mi>\n        <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n        <mi>Y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f:X\\to Y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/abd1e080abef4bbdab67b43819c6431e7561361c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:10.583ex; height:2.509ex;" alt="f:X\\to Y"/></span> such that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f({\\vec {x}})\\sim y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <mo>&#x223C;<!-- \xe2\x88\xbc --></mo>\n        <mi>y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f({\\vec {x}})\\sim y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b6f6d2201a45b4626332d3ec00e7bcd3abdeac4e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.672ex; height:2.843ex;" alt="f({\\vec  {x}})\\sim y"/></span>. Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\mathcal {H}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;" alt="{\\mathcal {H}}"/></span> be a space of functions <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f:X\\to Y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo>:</mo>\n        <mi>X</mi>\n        <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n        <mi>Y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f:X\\to Y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/abd1e080abef4bbdab67b43819c6431e7561361c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:10.583ex; height:2.509ex;" alt="f:X\\to Y"/></span> called the hypothesis space. The hypothesis space is the space of functions the algorithm will search through. Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle V(f({\\vec {x}}),y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>V</mi>\n        <mo stretchy="false">(</mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle V(f({\\vec {x}}),y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5b6f4858385026efb76bd83a1a5d640cecaee985" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.204ex; height:2.843ex;" alt="V(f({\\vec  {x}}),y)"/></span> be the <a href="/wiki/Loss_function" title="Loss function">loss function</a>, a metric for the difference between the predicted value <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f({\\vec {x}})}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f({\\vec {x}})}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/546ff1db2de71c7abcb09ef533f42dad5e89bf19" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.418ex; height:2.843ex;" alt="f({\\vec {x}})"/></span> and the actual value <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span>. The <a href="/w/index.php?title=Expected_risk&amp;action=edit&amp;redlink=1" class="new" title="Expected risk (page does not exist)">expected risk</a> is defined to be\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle I[f]=\\displaystyle \\int _{X\\times Y}V(f({\\vec {x}}),y)\\,p({\\vec {x}},y)\\,d{\\vec {x}}\\,dy}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>I</mi>\n        <mo stretchy="false">[</mo>\n        <mi>f</mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mstyle displaystyle="true" scriptlevel="0">\n          <msub>\n            <mo>&#x222B;<!-- \xe2\x88\xab --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>X</mi>\n              <mo>&#x00D7;<!-- \xc3\x97 --></mo>\n              <mi>Y</mi>\n            </mrow>\n          </msub>\n          <mi>V</mi>\n          <mo stretchy="false">(</mo>\n          <mi>f</mi>\n          <mo stretchy="false">(</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mover>\n                <mi>x</mi>\n                <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n              </mover>\n            </mrow>\n          </mrow>\n          <mo stretchy="false">)</mo>\n          <mo>,</mo>\n          <mi>y</mi>\n          <mo stretchy="false">)</mo>\n          <mspace width="thinmathspace" />\n          <mi>p</mi>\n          <mo stretchy="false">(</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mover>\n                <mi>x</mi>\n                <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n              </mover>\n            </mrow>\n          </mrow>\n          <mo>,</mo>\n          <mi>y</mi>\n          <mo stretchy="false">)</mo>\n          <mspace width="thinmathspace" />\n          <mi>d</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mrow class="MJX-TeXAtom-ORD">\n              <mover>\n                <mi>x</mi>\n                <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n              </mover>\n            </mrow>\n          </mrow>\n          <mspace width="thinmathspace" />\n          <mi>d</mi>\n          <mi>y</mi>\n        </mstyle>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle I[f]=\\displaystyle \\int _{X\\times Y}V(f({\\vec {x}}),y)\\,p({\\vec {x}},y)\\,d{\\vec {x}}\\,dy}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7c97de659352fa60d6624a1f54f4d3f0b32c73af" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.338ex; width:35.466ex; height:5.676ex;" alt="{\\displaystyle I[f]=\\displaystyle \\int _{X\\times Y}V(f({\\vec {x}}),y)\\,p({\\vec {x}},y)\\,d{\\vec {x}}\\,dy}"/></span></dd></dl>\n<p>The target function, the best possible function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> that can be\nchosen, is given by the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> that satisfies\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f=\\inf _{h\\in {\\mathcal {H}}}I[h]}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo>=</mo>\n        <munder>\n          <mo movablelimits="true" form="prefix">inf</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>h</mi>\n            <mo>&#x2208;<!-- \xe2\x88\x88 --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n              </mrow>\n            </mrow>\n          </mrow>\n        </munder>\n        <mi>I</mi>\n        <mo stretchy="false">[</mo>\n        <mi>h</mi>\n        <mo stretchy="false">]</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f=\\inf _{h\\in {\\mathcal {H}}}I[h]}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/47c982d6049c9ce70930b327589b5ff00915406f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.171ex; width:12ex; height:4.176ex;" alt="{\\displaystyle f=\\inf _{h\\in {\\mathcal {H}}}I[h]}"/></span></dd></dl>\n<p>Because the probability distribution <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p({\\vec {x}},y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p({\\vec {x}},y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1595e98c5caecb110c42a3b688b2e2c294220fa9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:6.587ex; height:2.843ex;" alt="p({\\vec  {x}},y)"/></span> is unknown, a\nproxy measure for the expected risk must be used. This measure is based on the training set, a sample from this unknown probability distribution. It is called the <a href="/w/index.php?title=Empirical_risk&amp;action=edit&amp;redlink=1" class="new" title="Empirical risk (page does not exist)">empirical risk</a>\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle I_{S}[f]={\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>I</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>S</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">[</mo>\n        <mi>f</mi>\n        <mo stretchy="false">]</mo>\n        <mo>=</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mfrac>\n            <mn>1</mn>\n            <mi>n</mi>\n          </mfrac>\n        </mrow>\n        <mstyle displaystyle="true" scriptlevel="0">\n          <munderover>\n            <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n              <mo>=</mo>\n              <mn>1</mn>\n            </mrow>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>n</mi>\n            </mrow>\n          </munderover>\n          <mi>V</mi>\n          <mo stretchy="false">(</mo>\n          <mi>f</mi>\n          <mo stretchy="false">(</mo>\n          <msub>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mrow class="MJX-TeXAtom-ORD">\n                <mover>\n                  <mi>x</mi>\n                  <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n                </mover>\n              </mrow>\n            </mrow>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n            </mrow>\n          </msub>\n          <mo stretchy="false">)</mo>\n          <mo>,</mo>\n          <msub>\n            <mi>y</mi>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n            </mrow>\n          </msub>\n          <mo stretchy="false">)</mo>\n        </mstyle>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle I_{S}[f]={\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0418e949bbea67e3cdbe4455429c3af2c3f09781" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:26.133ex; height:6.843ex;" alt="I_{S}[f]={\\frac  {1}{n}}\\displaystyle \\sum _{{i=1}}^{n}V(f({\\vec  {x}}_{i}),y_{i})"/></span></dd></dl>\n<p>A learning algorithm that chooses the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f_{S}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>f</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>S</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f_{S}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2b44c97f83aebb50c3fd26b567ff9b005dc7b82b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.432ex; height:2.509ex;" alt="f_S"/></span> that minimizes\nthe empirical risk is called <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">empirical risk minimization</a>.\n</p>\n<h2><span class="mw-headline" id="Loss_functions">Loss functions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=3" title="Edit section: Loss functions">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The choice of loss function is a determining factor on the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f_{S}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>f</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>S</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f_{S}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2b44c97f83aebb50c3fd26b567ff9b005dc7b82b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.432ex; height:2.509ex;" alt="f_S"/></span> that will be chosen by the learning algorithm. The loss function\nalso affects the convergence rate for an algorithm. It is important for the loss function to be convex.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup>\n</p><p>Different loss functions are used depending on whether the problem is\none of regression or one of classification.\n</p>\n<h3><span class="mw-headline" id="Regression">Regression</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=4" title="Edit section: Regression">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The most common loss function for regression is the square loss function (also known as the <a href="/wiki/L2-norm" class="mw-redirect" title="L2-norm">L2-norm</a>). This familiar loss function is used in <a href="/w/index.php?title=Ordinary_Least_Squares_regression&amp;action=edit&amp;redlink=1" class="new" title="Ordinary Least Squares regression (page does not exist)">Ordinary Least Squares regression</a>. The form is:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle V(f({\\vec {x}}),y)=(y-f({\\vec {x}}))^{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>V</mi>\n        <mo stretchy="false">(</mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <msup>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle V(f({\\vec {x}}),y)=(y-f({\\vec {x}}))^{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c971ef7591ca3bc4c5d7642d8f90369b29992a53" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:24.579ex; height:3.176ex;" alt="V(f({\\vec  {x}}),y)=(y-f({\\vec  {x}}))^{2}"/></span></dd></dl>\n<p>The absolute value loss (also known as the <a href="/wiki/L1-norm" class="mw-redirect" title="L1-norm">L1-norm</a>) is also sometimes used:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle V(f({\\vec {x}}),y)=|y-f({\\vec {x}})|}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>V</mi>\n        <mo stretchy="false">(</mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>y</mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle V(f({\\vec {x}}),y)=|y-f({\\vec {x}})|}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a9c353d1b2ca9828d0ab260278ba4b914e308cdd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:23.009ex; height:2.843ex;" alt="V(f({\\vec  {x}}),y)=|y-f({\\vec  {x}})|"/></span></dd></dl>\n<h3><span class="mw-headline" id="Classification">Classification</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=5" title="Edit section: Classification">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Statistical_classification" title="Statistical classification">Statistical classification</a></div>\n<p>In some sense the 0-1 <a href="/wiki/Indicator_function" title="Indicator function">indicator function</a> is the most natural loss function for classification. It takes the value 0 if the predicted output is the same as the actual output, and it takes the value 1 if the predicted output is different from the actual output. For binary classification with <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle Y=\\{-1,1\\}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>Y</mi>\n        <mo>=</mo>\n        <mo fence="false" stretchy="false">{</mo>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mn>1</mn>\n        <mo>,</mo>\n        <mn>1</mn>\n        <mo fence="false" stretchy="false">}</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle Y=\\{-1,1\\}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4916f8d7711119d44385e1d2f628cc139de2c953" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.364ex; height:2.843ex;" alt="{\\displaystyle Y=\\{-1,1\\}}"/></span>, this is:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle V(f({\\vec {x}}),y)=\\theta (-yf({\\vec {x}}))}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>V</mi>\n        <mo stretchy="false">(</mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n        <mo stretchy="false">(</mo>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>y</mi>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>x</mi>\n              <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle V(f({\\vec {x}}),y)=\\theta (-yf({\\vec {x}}))}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6aed24bedecfd114ed5bc77e5fdb1f36537d9330" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:23.583ex; height:2.843ex;" alt="{\\displaystyle V(f({\\vec {x}}),y)=\\theta (-yf({\\vec {x}}))}"/></span></dd></dl>\n<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\theta }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\theta }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;" alt="\\theta "/></span> is the <a href="/wiki/Heaviside_step_function" title="Heaviside step function">Heaviside step function</a>.\n</p>\n<h2><span class="mw-headline" id="Regularization">Regularization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=6" title="Edit section: Regularization">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Overfitting_on_Training_Set_Data.pdf" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Overfitting_on_Training_Set_Data.pdf/page1-220px-Overfitting_on_Training_Set_Data.pdf.jpg" decoding="async" width="220" height="215" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Overfitting_on_Training_Set_Data.pdf/page1-330px-Overfitting_on_Training_Set_Data.pdf.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Overfitting_on_Training_Set_Data.pdf/page1-440px-Overfitting_on_Training_Set_Data.pdf.jpg 2x" data-file-width="760" data-file-height="743" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Overfitting_on_Training_Set_Data.pdf" class="internal" title="Enlarge"></a></div>This image represents an example of overfitting in machine learning. The red dots represent training set data. The green line represents the true functional relationship, while the blue line shows the learned function, which has fallen victim to overfitting.</div></div></div>\n<p>In machine learning problems, a major problem that arises is that of <a href="/wiki/Overfitting" title="Overfitting">overfitting</a>. Because learning is a prediction problem, the goal is not to find a function that most closely fits the (previously observed) data, but to find one that will most accurately predict output from future input. <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a> runs this risk of overfitting: finding a function that matches the data exactly but does not predict future output well.\n</p><p>Overfitting is symptomatic of unstable solutions; a small perturbation in the training set data would cause a large variation in the learned function. It can be shown that if the stability for the solution can be guaranteed, generalization and consistency are guaranteed as well.<sup id="cite_ref-6" class="reference"><a href="#cite_note-6">&#91;6&#93;</a></sup><sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup> <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">Regularization</a> can solve the overfitting problem and give\nthe problem stability.\n</p><p>Regularization can be accomplished by restricting the hypothesis space <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\mathcal {H}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;" alt="{\\mathcal {H}}"/></span>. A common example would be restricting <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\mathcal {H}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;" alt="{\\mathcal {H}}"/></span> to linear functions: this can be seen as a reduction to the standard problem of <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a>. <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\mathcal {H}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;" alt="{\\mathcal {H}}"/></span> could also be restricted to polynomial of degree <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:1.259ex; height:2.009ex;" alt="p"/></span>, exponentials, or bounded functions on <a href="/wiki/Lp_space" title="Lp space">L1</a>. Restriction of the hypothesis space avoids overfitting because the form of the potential functions are limited, and so does not allow for the choice of a function that gives empirical risk arbitrarily close to zero.\n</p><p>One example of regularization is <a href="/wiki/Tikhonov_regularization" title="Tikhonov regularization">Tikhonov regularization</a>. This consists of minimizing\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})+\\gamma \\|f\\|_{\\mathcal {H}}^{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mfrac>\n            <mn>1</mn>\n            <mi>n</mi>\n          </mfrac>\n        </mrow>\n        <mstyle displaystyle="true" scriptlevel="0">\n          <munderover>\n            <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n              <mo>=</mo>\n              <mn>1</mn>\n            </mrow>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>n</mi>\n            </mrow>\n          </munderover>\n          <mi>V</mi>\n          <mo stretchy="false">(</mo>\n          <mi>f</mi>\n          <mo stretchy="false">(</mo>\n          <msub>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mrow class="MJX-TeXAtom-ORD">\n                <mover>\n                  <mi>x</mi>\n                  <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n                </mover>\n              </mrow>\n            </mrow>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n            </mrow>\n          </msub>\n          <mo stretchy="false">)</mo>\n          <mo>,</mo>\n          <msub>\n            <mi>y</mi>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n            </mrow>\n          </msub>\n          <mo stretchy="false">)</mo>\n          <mo>+</mo>\n          <mi>&#x03B3;<!-- \xce\xb3 --></mi>\n          <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n          <mi>f</mi>\n          <msubsup>\n            <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n              </mrow>\n            </mrow>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mn>2</mn>\n            </mrow>\n          </msubsup>\n        </mstyle>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})+\\gamma \\|f\\|_{\\mathcal {H}}^{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d281a9698fde8d2015871615891a677457d0a4e2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:27.474ex; height:6.843ex;" alt="{\\displaystyle {\\frac {1}{n}}\\displaystyle \\sum _{i=1}^{n}V(f({\\vec {x}}_{i}),y_{i})+\\gamma \\|f\\|_{\\mathcal {H}}^{2}}"/></span></dd></dl>\n<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\gamma }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03B3;<!-- \xce\xb3 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\gamma }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a223c880b0ce3da8f64ee33c4f0010beee400b1a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:1.262ex; height:2.176ex;" alt="\\gamma "/></span> is a fixed and positive parameter, the regularization parameter. Tikhonov regularization ensures existence, uniqueness, and stability of the solution.<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup>\n</p>\n<div style="clear:both;"></div>\n<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=7" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a href="/wiki/Reproducing_kernel_Hilbert_spaces" class="mw-redirect" title="Reproducing kernel Hilbert spaces">Reproducing kernel Hilbert spaces</a> are a useful choice for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\mathcal {H}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;" alt="{\\mathcal {H}}"/></span>.</li>\n<li><a href="/wiki/Proximal_gradient_methods_for_learning" title="Proximal gradient methods for learning">Proximal gradient methods for learning</a></li></ul>\n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit&amp;section=8" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="reflist" style="list-style-type: decimal;">\n<div class="mw-references-wrap"><ol class="references">\n<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><a href="/wiki/Trevor_Hastie" title="Trevor Hastie">Trevor Hastie</a>, Robert Tibshirani, Jerome Friedman (2009) <i>The Elements of Statistical Learning</i>, Springer-Verlag <style data-mw-deduplicate="TemplateStyles:r886058088">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\\"""\\"""\'""\'"}.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-387-84857-0" title="Special:BookSources/978-0-387-84857-0">978-0-387-84857-0</a>.</span>\n</li>\n<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite class="citation book"><a href="/wiki/Mehryar_Mohri" title="Mehryar Mohri">Mohri, Mehryar</a>; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). <i>Foundations of Machine Learning</i>. USA, Massachusetts: MIT Press. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9780262018258" title="Special:BookSources/9780262018258"><bdi>9780262018258</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Foundations+of+Machine+Learning&amp;rft.place=USA%2C+Massachusetts&amp;rft.pub=MIT+Press&amp;rft.date=2012&amp;rft.isbn=9780262018258&amp;rft.aulast=Mohri&amp;rft.aufirst=Mehryar&amp;rft.au=Rostamizadeh%2C+Afshin&amp;rft.au=Talwalkar%2C+Ameet&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStatistical+learning+theory" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">Gagan Sidhu, Brian Caffo. <a rel="nofollow" class="external text" href="https://projecteuclid.org/download/pdfview_1/euclid.aoas/1404229520">Exploiting pitcher decision-making using Reinforcement Learning</a>. <i>Annals of Applied Statistics</i></span>\n</li>\n<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">Tomaso Poggio, Lorenzo Rosasco, et al. <i>Statistical Learning Theory and Applications</i>, 2012, <a rel="nofollow" class="external text" href="https://www.mit.edu/~9.520/spring12/slides/class01/class01.pdf">Class 1</a></span>\n</li>\n<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text">Rosasco, L., Vito, E.D., Caponnetto, A., Fiana, M., and Verri A. 2004. <i>Neural computation</i> Vol 16, pp 1063-1076</span>\n</li>\n<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text">Vapnik, V.N. and Chervonenkis, A.Y. 1971. <a rel="nofollow" class="external text" href="http://ai2-s2-pdfs.s3.amazonaws.com/a36b/028d024bf358c4af1a5e1dc3ca0aed23b553.pdf">On the uniform convergence of relative frequencies of events to their probabilities</a>. <i>Theory of Probability and Its Applications</i> Vol 16, pp 264-280.</span>\n</li>\n<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">Mukherjee, S., Niyogi, P. Poggio, T., and Rifkin, R. 2006. <a rel="nofollow" class="external text" href="https://link.springer.com/article/10.1007/s10444-004-7634-z">Learning theory: stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization</a>. <i>Advances in Computational Mathematics</i>. Vol 25, pp 161-193.</span>\n</li>\n<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text">Tomaso Poggio, Lorenzo Rosasco, et al. <i>Statistical Learning Theory and Applications</i>, 2012, <a rel="nofollow" class="external text" href="https://www.mit.edu/~9.520/spring12/slides/class02/class02.pdf">Class 2</a></span>\n</li>\n</ol></div></div>\n<!-- \nNewPP limit report\nParsed by mw1324\nCached time: 20191031123432\nCache expiry: 2592000\nDynamic content: false\nComplications: [vary\xe2\x80\x90revision\xe2\x80\x90sha1]\nCPU time usage: 0.268 seconds\nReal time usage: 0.430 seconds\nPreprocessor visited node count: 810/1000000\nPreprocessor generated node count: 0/1500000\nPost\xe2\x80\x90expand include size: 30381/2097152 bytes\nTemplate argument size: 1192/2097152 bytes\nHighest expansion depth: 15/40\nExpensive parser function count: 0/500\nUnstrip recursion depth: 1/20\nUnstrip post\xe2\x80\x90expand size: 9676/5000000 bytes\nNumber of Wikibase entities loaded: 0/400\nLua time usage: 0.056/10.000 seconds\nLua memory usage: 2.3 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  263.899      1 -total\n 51.67%  136.348      1 Template:Reflist\n 24.04%   63.429      1 Template:Isbn\n 21.28%   56.155      1 Template:Cite_Mehryar_Afshin_Ameet_2012\n 20.66%   54.514      1 Template:Machine_learning_bar\n 20.27%   53.484      1 Template:Cite_book\n 19.39%   51.161      1 Template:Sidebar_with_collapsible_lists\n 13.53%   35.705      1 Template:Catalog_lookup_link\n 12.75%   33.638      1 Template:Longitem\n 11.59%   30.586      1 Template:Nobold\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:1053303-0!canonical!math=5 and timestamp 20191031123431 and revision id 915171435\n -->\n</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>\n\t\t\n\t\t<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Statistical_learning_theory&amp;oldid=915171435">https://en.wikipedia.org/w/index.php?title=Statistical_learning_theory&amp;oldid=915171435</a>"</div>\n\t\t\n\t\t<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li><li><a href="/wiki/Category:Estimation_theory" title="Category:Estimation theory">Estimation theory</a></li></ul></div></div>\n\t\t<div class="visualClear"></div>\n\t\t\n\t</div>\n</div>\n<div id=\'mw-data-after-content\'>\n\t<div class="read-more-container"></div>\n</div>\n\n\n\t\t<div id="mw-navigation">\n\t\t\t<h2>Navigation menu</h2>\n\t\t\t<div id="mw-head">\n\t\t\t\t\t\t\t\t\t<div id="p-personal" role="navigation" aria-labelledby="p-personal-label">\n\t\t\t\t\t\t<h3 id="p-personal-label">Personal tools</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Statistical+learning+theory" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Statistical+learning+theory" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t<div id="left-navigation">\n\t\t\t\t\t\t\t\t\t\t<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">\n\t\t\t\t\t\t<h3 id="p-namespaces-label">Namespaces</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="ca-nstab-main" class="selected"><a href="/wiki/Statistical_learning_theory" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Statistical_learning_theory" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">\n\t\t\t\t\t\t\t\t\t\t\t\t<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />\n\t\t\t\t\t\t<h3 id="p-variants-label">\n\t\t\t\t\t\t\t<span>Variants</span>\n\t\t\t\t\t\t</h3>\n\t\t\t\t\t\t<ul class="menu">\n\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t<div id="right-navigation">\n\t\t\t\t\t\t\t\t\t\t<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">\n\t\t\t\t\t\t<h3 id="p-views-label">Views</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="ca-view" class="collapsible selected"><a href="/wiki/Statistical_learning_theory">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Statistical_learning_theory&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Statistical_learning_theory&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">\n\t\t\t\t\t\t<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />\n\t\t\t\t\t\t<h3 id="p-cactions-label"><span>More</span></h3>\n\t\t\t\t\t\t<ul class="menu">\n\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-search" role="search">\n\t\t\t\t\t\t<h3>\n\t\t\t\t\t\t\t<label for="searchInput">Search</label>\n\t\t\t\t\t\t</h3>\n\t\t\t\t\t\t<form action="/w/index.php" id="searchform">\n\t\t\t\t\t\t\t<div id="simpleSearch">\n\t\t\t\t\t\t\t\t<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</form>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t<div id="mw-panel">\n\t\t\t\t<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a></div>\n\t\t\t\t\t\t<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">\n\t\t\t<h3 id="p-navigation-label">Navigation</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content \xe2\x80\x93 the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-interaction" aria-labelledby="p-interaction-label">\n\t\t\t<h3 id="p-interaction-label">Interaction</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">\n\t\t\t<h3 id="p-tb-label">Tools</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Statistical_learning_theory" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Statistical_learning_theory" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Statistical_learning_theory&amp;oldid=915171435" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Statistical_learning_theory&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q7604400" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Statistical_learning_theory&amp;id=915171435" title="Information on how to cite this page">Cite this page</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">\n\t\t\t<h3 id="p-coll-print_export-label">Print/export</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Statistical+learning+theory">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Statistical+learning+theory&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Statistical_learning_theory&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label">\n\t\t\t<h3 id="p-lang-label">Languages</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Th%C3%A9orie_de_l%27apprentissage_statistique" title="Th\xc3\xa9orie de l&#039;apprentissage statistique \xe2\x80\x93 French" lang="fr" hreflang="fr" class="interlanguage-link-target">Fran\xc3\xa7ais</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%ED%86%B5%EA%B3%84%EC%A0%81_%ED%95%99%EC%8A%B5%EC%9D%B4%EB%A1%A0" title="\xed\x86\xb5\xea\xb3\x84\xec\xa0\x81 \xed\x95\x99\xec\x8a\xb5\xec\x9d\xb4\xeb\xa1\xa0 \xe2\x80\x93 Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">\xed\x95\x9c\xea\xb5\xad\xec\x96\xb4</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%82%D0%B5%D0%BE%D1%80%D0%B8%D1%8F_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D1%8F" title="\xd0\xa1\xd1\x82\xd0\xb0\xd1\x82\xd0\xb8\xd1\x81\xd1\x82\xd0\xb8\xd1\x87\xd0\xb5\xd1\x81\xd0\xba\xd0\xb0\xd1\x8f \xd1\x82\xd0\xb5\xd0\xbe\xd1\x80\xd0\xb8\xd1\x8f \xd0\xbe\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd1\x8f \xe2\x80\x93 Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">\xd0\xa0\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%A2%D0%B5%D0%BE%D1%80%D1%96%D1%8F_%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%BD%D0%BE%D0%B3%D0%BE_%D0%BD%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F" title="\xd0\xa2\xd0\xb5\xd0\xbe\xd1\x80\xd1\x96\xd1\x8f \xd1\x81\xd1\x82\xd0\xb0\xd1\x82\xd0\xb8\xd1\x81\xd1\x82\xd0\xb8\xd1\x87\xd0\xbd\xd0\xbe\xd0\xb3\xd0\xbe \xd0\xbd\xd0\xb0\xd0\xb2\xd1\x87\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8f \xe2\x80\x93 Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">\xd0\xa3\xd0\xba\xd1\x80\xd0\xb0\xd1\x97\xd0\xbd\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA" title="\xe7\xbb\x9f\xe8\xae\xa1\xe5\xad\xa6\xe4\xb9\xa0\xe7\x90\x86\xe8\xae\xba \xe2\x80\x93 Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">\xe4\xb8\xad\xe6\x96\x87</a></li>\t\t\t\t</ul>\n\t\t\t\t<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q7604400#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>\t\t\t</div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t</div>\n\t\t\t\t<div id="footer" role="contentinfo">\n\t\t\t\t\t\t<ul id="footer-info">\n\t\t\t\t\t\t\t\t<li id="footer-info-lastmod"> This page was last edited on 11 September 2019, at 17:02<span class="anonymous-show">&#160;(UTC)</span>.</li>\n\t\t\t\t\t\t\t\t<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia\xc2\xae is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t<ul id="footer-places">\n\t\t\t\t\t\t\t\t<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Statistical_learning_theory&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>\n\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t\t\t\t\t<ul id="footer-icons" class="noprint">\n\t\t\t\t\t\t\t\t\t\t<li id="footer-copyrightico">\n\t\t\t\t\t\t<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t<li id="footer-poweredbyico">\n\t\t\t\t\t\t<a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t<div style="clear: both;"></div>\n\t\t</div>\n\t\t\n\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.268","walltime":"0.430","ppvisitednodes":{"value":810,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":30381,"limit":2097152},"templateargumentsize":{"value":1192,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":0,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":9676,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  263.899      1 -total"," 51.67%  136.348      1 Template:Reflist"," 24.04%   63.429      1 Template:Isbn"," 21.28%   56.155      1 Template:Cite_Mehryar_Afshin_Ameet_2012"," 20.66%   54.514      1 Template:Machine_learning_bar"," 20.27%   53.484      1 Template:Cite_book"," 19.39%   51.161      1 Template:Sidebar_with_collapsible_lists"," 13.53%   35.705      1 Template:Catalog_lookup_link"," 12.75%   33.638      1 Template:Longitem"," 11.59%   30.586      1 Template:Nobold"]},"scribunto":{"limitreport-timeusage":{"value":"0.056","limit":"10.000"},"limitreport-memusage":{"value":2412778,"limit":52428800}},"cachereport":{"origin":"mw1324","timestamp":"20191031123432","ttl":2592000,"transientcontent":false}}});});</script>\n<script type="application/ld+json">{"@context":"https:\\/\\/schema.org","@type":"Article","name":"Statistical learning theory","url":"https:\\/\\/en.wikipedia.org\\/wiki\\/Statistical_learning_theory","sameAs":"http:\\/\\/www.wikidata.org\\/entity\\/Q7604400","mainEntity":"http:\\/\\/www.wikidata.org\\/entity\\/Q7604400","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png"}},"datePublished":"2004-10-09T22:10:29Z","dateModified":"2019-09-11T17:02:27Z","image":"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/f\\/fe\\/Kernel_Machine.svg","headline":"Wikimedia disambiguation page"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":91,"wgHostname":"mw1258"});});</script>\n</body>\n</html>\n'