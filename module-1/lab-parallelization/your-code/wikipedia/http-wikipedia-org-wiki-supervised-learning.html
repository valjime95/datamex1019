b'<!DOCTYPE html>\n<html class="client-nojs" lang="en" dir="ltr">\n<head>\n<meta charset="UTF-8"/>\n<title>Supervised learning - Wikipedia</title>\n<script>document.documentElement.className="client-js";RLCONF={"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Supervised_learning","wgTitle":"Supervised learning","wgCurRevisionId":920525193,"wgRevisionId":920525193,"wgArticleId":20926,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Supervised learning"],"wgBreakFrames":!1,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],"wgRelevantPageName":"Supervised_learning","wgRelevantArticleId":20926,"wgRequestId":"XbT-pApAAD4AAFBFNtMAAACI","wgCSPNonce":!1,"wgIsProbablyEditable":!0,\n"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q334384","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.toc.styles":"ready",\n"wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp",\n"skins.vector.js"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\\\","watchToken":"+\\\\","csrfToken":"+\\\\"});\n});});</script>\n<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>\n<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>\n<meta name="ResourceLoaderDynamicStyles" content=""/>\n<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>\n<meta name="generator" content="MediaWiki 1.35.0-wmf.3"/>\n<meta name="referrer" content="origin"/>\n<meta name="referrer" content="origin-when-crossorigin"/>\n<meta name="referrer" content="origin-when-cross-origin"/>\n<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/1200px-Kernel_Machine.svg.png"/>\n<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Supervised_learning"/>\n<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Supervised_learning&amp;action=edit"/>\n<link rel="edit" title="Edit this page" href="/w/index.php?title=Supervised_learning&amp;action=edit"/>\n<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>\n<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>\n<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>\n<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>\n<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>\n<link rel="canonical" href="https://en.wikipedia.org/wiki/Supervised_learning"/>\n<link rel="dns-prefetch" href="//login.wikimedia.org"/>\n<link rel="dns-prefetch" href="//meta.wikimedia.org" />\n<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->\n</head>\n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Supervised_learning rootpage-Supervised_learning skin-vector action-view">\n<div id="mw-page-base" class="noprint"></div>\n<div id="mw-head-base" class="noprint"></div>\n<div id="content" class="mw-body" role="main">\n\t<a id="top"></a>\n\t<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>\n\t<div class="mw-indicators mw-body-content">\n</div>\n\n\t<h1 id="firstHeading" class="firstHeading" lang="en">Supervised learning</h1>\n\t\n\t<div id="bodyContent" class="mw-body-content">\n\t\t<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>\n\t\t<div id="contentSub"></div>\n\t\t\n\t\t\n\t\t\n\t\t<div id="jump-to-nav"></div>\n\t\t<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>\n\t\t<a class="mw-jump-link" href="#p-search">Jump to search</a>\n\t\t<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></div>\n<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br /><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a href="/wiki/File:Kernel_Machine.svg" class="image"><img alt="Kernel Machine.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" decoding="async" width="220" height="100" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" data-file-width="512" data-file-height="233" /></a></td></tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>\n<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>\n<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>\n<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>\n<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>\n<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>\n<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>\n<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>\n<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>\n<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>\n<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>\n<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>\n<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>\n<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>\n<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a class="mw-selflink selflink">Supervised learning</a><br /><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>&#160;&#8226;&#32;<b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>\n<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>\n<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>\n<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>\n<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>\n<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>\n<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>\n<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>\n<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>\n<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>\n<li><a href="/wiki/CURE_data_clustering_algorithm" class="mw-redirect" title="CURE data clustering algorithm">CURE</a></li>\n<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>\n<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>\n<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation\xe2\x80\x93maximization algorithm">Expectation\xe2\x80\x93maximization (EM)</a></li>\n<li><br /><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>\n<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>\n<li><a href="/wiki/Mean-shift" class="mw-redirect" title="Mean-shift">Mean-shift</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>\n<li><a href="/wiki/Canonical_correlation_analysis" class="mw-redirect" title="Canonical correlation analysis">CCA</a></li>\n<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>\n<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>\n<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>\n<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>\n<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>\n<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/K-nearest_neighbors_classification" class="mw-redirect" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_networks" class="mw-redirect" title="Artificial neural networks">Artificial neural networks</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>\n<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>\n<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>\n<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>\n<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>\n<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>\n<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>\n<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>\n<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>\n<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>\n<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>\n<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>\n<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State\xe2\x80\x93action\xe2\x80\x93reward\xe2\x80\x93state\xe2\x80\x93action">SARSA</a></li>\n<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Bias%E2%80%93variance_dilemma" class="mw-redirect" title="Bias\xe2\x80\x93variance dilemma">Bias\xe2\x80\x93variance dilemma</a></li>\n<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>\n<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>\n<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>\n<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>\n<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>\n<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik\xe2\x80\x93Chervonenkis theory">VC theory</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NIPS</a></li>\n<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>\n<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>\n<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>\n<li><a rel="nofollow" class="external text" href="https://arxiv.org/list/cs.LG/recent">ArXiv:cs.LG</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>\n<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>\n<p><b>Supervised learning</b> is the <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> task of learning a function that maps an input to an output based on example input-output pairs.<sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup> It infers a function from <i><span id="LABELLED_DATA"></span><span id="labeled_&#91;&#91;training_set&#124;training_data&#93;&#93;">labeled <a href="/wiki/Training_set" class="mw-redirect" title="Training set">training data</a></span></i> consisting of a set of <i>training examples</i>.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup>  In supervised learning, each example is a <i>pair</i> consisting of an input object (typically a vector) and a desired output value (also called the <i>supervisory signal</i>).  A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see <a href="/wiki/Inductive_bias" title="Inductive bias">inductive bias</a>).\n</p><p>The parallel task in human and animal psychology is often referred to as <a href="/wiki/Concept_learning" title="Concept learning">concept learning</a>.\n</p>\n<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>\n<ul>\n<li class="toclevel-1 tocsection-1"><a href="#Steps"><span class="tocnumber">1</span> <span class="toctext">Steps</span></a></li>\n<li class="toclevel-1 tocsection-2"><a href="#Algorithm_choice"><span class="tocnumber">2</span> <span class="toctext">Algorithm choice</span></a>\n<ul>\n<li class="toclevel-2 tocsection-3"><a href="#Bias-variance_tradeoff"><span class="tocnumber">2.1</span> <span class="toctext">Bias-variance tradeoff</span></a></li>\n<li class="toclevel-2 tocsection-4"><a href="#Function_complexity_and_amount_of_training_data"><span class="tocnumber">2.2</span> <span class="toctext">Function complexity and amount of training data</span></a></li>\n<li class="toclevel-2 tocsection-5"><a href="#Dimensionality_of_the_input_space"><span class="tocnumber">2.3</span> <span class="toctext">Dimensionality of the input space</span></a></li>\n<li class="toclevel-2 tocsection-6"><a href="#Noise_in_the_output_values"><span class="tocnumber">2.4</span> <span class="toctext">Noise in the output values</span></a></li>\n<li class="toclevel-2 tocsection-7"><a href="#Other_factors_to_consider_(important)"><span class="tocnumber">2.5</span> <span class="toctext">Other factors to consider (important)</span></a></li>\n<li class="toclevel-2 tocsection-8"><a href="#Algorithms"><span class="tocnumber">2.6</span> <span class="toctext">Algorithms</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-9"><a href="#How_supervised_learning_algorithms_work"><span class="tocnumber">3</span> <span class="toctext">How supervised learning algorithms work</span></a>\n<ul>\n<li class="toclevel-2 tocsection-10"><a href="#Empirical_risk_minimization"><span class="tocnumber">3.1</span> <span class="toctext">Empirical risk minimization</span></a></li>\n<li class="toclevel-2 tocsection-11"><a href="#Structural_risk_minimization"><span class="tocnumber">3.2</span> <span class="toctext">Structural risk minimization</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-12"><a href="#Generative_training"><span class="tocnumber">4</span> <span class="toctext">Generative training</span></a></li>\n<li class="toclevel-1 tocsection-13"><a href="#Generalizations"><span class="tocnumber">5</span> <span class="toctext">Generalizations</span></a></li>\n<li class="toclevel-1 tocsection-14"><a href="#Approaches_and_algorithms"><span class="tocnumber">6</span> <span class="toctext">Approaches and algorithms</span></a></li>\n<li class="toclevel-1 tocsection-15"><a href="#Applications"><span class="tocnumber">7</span> <span class="toctext">Applications</span></a></li>\n<li class="toclevel-1 tocsection-16"><a href="#General_issues"><span class="tocnumber">8</span> <span class="toctext">General issues</span></a></li>\n<li class="toclevel-1 tocsection-17"><a href="#See_also"><span class="tocnumber">9</span> <span class="toctext">See also</span></a></li>\n<li class="toclevel-1 tocsection-18"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>\n<li class="toclevel-1 tocsection-19"><a href="#External_links"><span class="tocnumber">11</span> <span class="toctext">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class="mw-headline" id="Steps">Steps</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=1" title="Edit section: Steps">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>In order to solve a given problem of supervised learning, one has to perform the following steps:\n</p>\n<ol><li>Determine the type of training examples. Before doing anything else, the user should decide what kind of data is to be used as a training set. In the case of <a href="/wiki/Handwriting_analysis" class="mw-redirect" title="Handwriting analysis">handwriting analysis</a>, for example, this might be a single handwritten character, an entire handwritten word, or an entire line of handwriting.</li>\n<li>Gather a training set. The training set needs to be representative of the real-world use of the function. Thus, a set of input objects is gathered and corresponding outputs are also gathered, either from human experts or from measurements.</li>\n<li>Determine the input feature representation of the learned function. The accuracy of the learned function depends strongly on how the input object is represented. Typically, the input object is transformed into a <a href="/wiki/Feature_vector" class="mw-redirect" title="Feature vector">feature vector</a>, which contains a number of features that are descriptive of the object. The number of features should not be too large, because of the <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>; but should contain enough information to accurately predict the output.</li>\n<li>Determine the structure of the learned function and corresponding learning algorithm. For example, the engineer may choose to use <a href="/wiki/Support_vector_machine" class="mw-redirect" title="Support vector machine">support vector machines</a> or <a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a>.</li>\n<li>Complete the design. Run the learning algorithm on the gathered training set. Some supervised learning algorithms require the user to determine certain control parameters. These parameters may be adjusted by optimizing performance on a subset (called a <i>validation</i> set) of the training set, or via <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross-validation</a>.</li>\n<li>Evaluate the accuracy of the learned function. After parameter adjustment and learning, the performance of the resulting function should be measured on a test set that is separate from the training set.</li></ol>\n<h2><span class="mw-headline" id="Algorithm_choice">Algorithm choice</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=2" title="Edit section: Algorithm choice">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>A wide range of supervised learning algorithms are available, each with its strengths and weaknesses. There is no single learning algorithm that works best on all supervised learning problems (see the <a href="/wiki/No_free_lunch_in_search_and_optimization" title="No free lunch in search and optimization">No free lunch theorem</a>).\n</p><p>There are four major issues to consider in supervised learning:\n</p>\n<h3><span class="mw-headline" id="Bias-variance_tradeoff">Bias-variance tradeoff</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=3" title="Edit section: Bias-variance tradeoff">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Bias-variance_dilemma" class="mw-redirect" title="Bias-variance dilemma">Bias-variance dilemma</a></div>\n<p>A first issue is the tradeoff between <i>bias</i> and <i>variance</i>.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup>  Imagine that we have available several different, but equally good, training data sets.  A learning algorithm is biased for a particular input <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>x</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="x"/></span> if, when trained on each of these data sets, it is systematically incorrect when predicting the correct output for <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>x</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="x"/></span>.  A learning algorithm has high variance for a particular input <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>x</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="x"/></span> if it predicts different output values when trained on different training sets.  The prediction error of a learned classifier is related to the sum of the bias and the variance of the learning algorithm.<sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup>  Generally, there is a tradeoff between bias and variance.  A learning algorithm with low bias must be "flexible" so that it can fit the data well.  But if the learning algorithm is too flexible, it will fit each training data set differently, and hence have high variance.  A key aspect of many supervised learning methods is that they are able to adjust this tradeoff between bias and variance (either automatically or by providing a bias/variance parameter that the user can adjust).\n</p>\n<h3><span class="mw-headline" id="Function_complexity_and_amount_of_training_data">Function complexity and amount of training data</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=4" title="Edit section: Function complexity and amount of training data">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The second issue is the amount of training data available relative to the complexity of the "true" function (classifier or regression function).  If the true function is simple, then an "inflexible" learning algorithm with high bias and low variance will be able to learn it from a small amount of data.  But if the true function is highly complex (e.g., because it involves complex interactions among many different input features and behaves differently in different parts of the input space), then the function will only be able to learn from a very large amount of training data and using a "flexible" learning algorithm with low bias and high variance.\n</p>\n<h3><span class="mw-headline" id="Dimensionality_of_the_input_space">Dimensionality of the input space</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=5" title="Edit section: Dimensionality of the input space">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>A third issue is the dimensionality of the input space.  If the input feature vectors have very high dimension, the learning problem can be difficult even if the true function only depends on a small number of those features.  This is because the many "extra" dimensions can confuse the learning algorithm and cause it to have high variance.  Hence, high input dimensional typically requires tuning the classifier to have low variance and high bias.  In practice, if the engineer can manually remove irrelevant features from the input data, this is likely to improve the accuracy of the learned function.  In addition, there are many algorithms for <a href="/wiki/Feature_selection" title="Feature selection">feature selection</a> that seek to identify the relevant features and discard the irrelevant ones.  This is an instance of the more general strategy of <a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">dimensionality reduction</a>, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm.\n</p>\n<h3><span class="mw-headline" id="Noise_in_the_output_values">Noise in the output values</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=6" title="Edit section: Noise in the output values">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>A fourth issue is the degree of noise in the desired output values (the supervisory <a href="/wiki/Target_variable" class="mw-redirect" title="Target variable">target variables</a>).  If the desired output values are often incorrect (because of human error or sensor errors), then the learning algorithm should not attempt to find a function that exactly matches the training examples.  Attempting to fit the data too carefully leads to <a href="/wiki/Overfitting" title="Overfitting">overfitting</a>.  You can overfit even when there are no measurement errors (stochastic noise) if the function you are trying to learn is too complex for your learning model. In such a situation, the part of the target function that cannot be modeled "corrupts" your training data - this phenomenon has been called <a href="/wiki/Deterministic_noise" title="Deterministic noise">deterministic noise</a>. When either type of noise is present, it is better to go with a higher bias, lower variance estimator.\n</p><p>In practice, there are several approaches to alleviate noise in the output values such as <a href="/wiki/Early_stopping" title="Early stopping">early stopping</a> to prevent <a href="/wiki/Overfitting" title="Overfitting">overfitting</a> as well as <a href="/wiki/Anomaly_detection" title="Anomaly detection">detecting</a> and removing the noisy training examples prior to training the supervised learning algorithm.  There are several algorithms that identify noisy training examples and removing the suspected noisy training examples prior to training has decreased <a href="/wiki/Generalization_error" title="Generalization error">generalization error</a> with <a href="/wiki/Statistical_significance" title="Statistical significance">statistical significance</a>.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup><sup id="cite_ref-6" class="reference"><a href="#cite_note-6">&#91;6&#93;</a></sup>\n</p>\n<h3><span id="Other_factors_to_consider_.28important.29"></span><span class="mw-headline" id="Other_factors_to_consider_(important)">Other factors to consider (important)</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=7" title="Edit section: Other factors to consider (important)">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Other factors to consider when choosing and applying a learning algorithm include the following:\n</p>\n<ul><li>Heterogeneity of the data.  If the feature vectors include features of many different kinds (discrete, discrete ordered, counts, continuous values), some algorithms are easier to apply than others.  Many algorithms, including <a href="/wiki/Support_Vector_Machines" class="mw-redirect" title="Support Vector Machines">Support Vector Machines</a>, <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a>, <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, <a href="/wiki/Artificial_neural_network" title="Artificial neural network">neural networks</a>, and <a href="/wiki/K-nearest_neighbor_algorithm" class="mw-redirect" title="K-nearest neighbor algorithm">nearest neighbor methods</a>, require that the input features be numerical and scaled to similar ranges (e.g., to the [-1,1] interval).  Methods that employ a distance function, such as <a href="/wiki/K-nearest_neighbor_algorithm" class="mw-redirect" title="K-nearest neighbor algorithm">nearest neighbor methods</a> and <a href="/wiki/Support_Vector_Machines" class="mw-redirect" title="Support Vector Machines">support vector machines with Gaussian kernels</a>, are particularly sensitive to this. An advantage of <a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a> is that they easily handle heterogeneous data.</li>\n<li>Redundancy in the data.  If the input features contain redundant information (e.g., highly correlated features), some learning algorithms (e.g., <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a>, <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, and <a href="/wiki/K-nearest_neighbor_algorithm" class="mw-redirect" title="K-nearest neighbor algorithm">distance based methods</a>) will perform poorly because of numerical instabilities.  These problems can often be solved by imposing some form of <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization</a>.</li>\n<li>Presence of interactions and non-linearities.  If each of the features makes an independent contribution to the output, then algorithms based on linear functions (e.g., <a href="/wiki/Linear_regression" title="Linear regression">linear regression</a>, <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a>, <a href="/wiki/Support_Vector_Machines" class="mw-redirect" title="Support Vector Machines">Support Vector Machines</a>, <a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes</a>) and distance functions (e.g., <a href="/wiki/K-nearest_neighbor_algorithm" class="mw-redirect" title="K-nearest neighbor algorithm">nearest neighbor methods</a>, <a href="/wiki/Support_Vector_Machines" class="mw-redirect" title="Support Vector Machines">support vector machines with Gaussian kernels</a>) generally perform well.  However, if there are complex interactions among features, then algorithms such as <a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a> and <a href="/wiki/Artificial_neural_network" title="Artificial neural network">neural networks</a> work better, because they are specifically designed to discover these interactions.  Linear methods can also be applied, but the engineer must manually specify the interactions when using them.</li></ul>\n<p>When considering a new application, the engineer can compare multiple learning algorithms and experimentally determine which one works best on the problem at hand (see <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross validation</a>).  Tuning the performance of a learning algorithm can be very time-consuming.  Given fixed resources, it is often better to spend more time collecting additional training data and more informative features than it is to spend extra time tuning the learning algorithms.\n</p>\n<h3><span class="mw-headline" id="Algorithms">Algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=8" title="Edit section: Algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>The most widely used learning algorithms are: \n</p>\n<ul><li><a href="/wiki/Support_Vector_Machines" class="mw-redirect" title="Support Vector Machines">Support Vector Machines</a></li>\n<li><a href="/wiki/Linear_regression" title="Linear regression">linear regression</a></li>\n<li><a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes</a></li>\n<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">linear discriminant analysis</a></li>\n<li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a></li>\n<li><a href="/wiki/K-nearest_neighbor_algorithm" class="mw-redirect" title="K-nearest neighbor algorithm">k-nearest neighbor algorithm</a></li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Neural Networks</a> (<a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a>)</li>\n<li><a href="/wiki/Similarity_learning" title="Similarity learning">Similarity learning</a></li></ul>\n<h2><span class="mw-headline" id="How_supervised_learning_algorithms_work">How supervised learning algorithms work</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=9" title="Edit section: How supervised learning algorithms work">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>Given a set of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle N}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>N</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle N}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5e3890c981ae85503089652feb48b191b57aae3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.064ex; height:2.176ex;" alt="N"/></span> training examples of the form <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\{(x_{1},y_{1}),...,(x_{N},\\;y_{N})\\}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo fence="false" stretchy="false">{</mo>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo>,</mo>\n        <mo>.</mo>\n        <mo>.</mo>\n        <mo>.</mo>\n        <mo>,</mo>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>N</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mspace width="thickmathspace" />\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>N</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo fence="false" stretchy="false">}</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\{(x_{1},y_{1}),...,(x_{N},\\;y_{N})\\}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3688abd5ec58027a9d879916c83b6890744ce4dd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:24.255ex; height:2.843ex;" alt="\\{(x_1, y_1), ..., (x_N,\\; y_N)\\}"/></span> such that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{i}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{i}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="x_{i}"/></span> is the <a href="/wiki/Feature_vector" class="mw-redirect" title="Feature vector">feature vector</a> of the i-th example and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y_{i}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y_{i}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/67d30d30b6c2dbe4d6f150d699de040937ecc95f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.939ex; height:2.009ex;" alt="y_{i}"/></span> is its label (i.e., class), a learning algorithm seeks a function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g:X\\to Y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n        <mo>:</mo>\n        <mi>X</mi>\n        <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n        <mi>Y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g:X\\to Y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5c825617c180ee9cbba1d56f8514978bf7c33b7c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:10.421ex; height:2.509ex;" alt="g: X \\to Y"/></span>, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle X}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>X</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"/></span> is the input space and\n<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle Y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>Y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle Y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"/></span> is the output space.  The function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> is an element of some space of possible functions <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle G}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>G</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle G}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.827ex; height:2.176ex;" alt="G"/></span>, usually called the <i>hypothesis space</i>.  It is sometimes convenient to\nrepresent <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> using a scoring function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f:X\\times Y\\to \\mathbb {R} }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo>:</mo>\n        <mi>X</mi>\n        <mo>&#x00D7;<!-- \xc3\x97 --></mo>\n        <mi>Y</mi>\n        <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mi mathvariant="double-struck">R</mi>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f:X\\times Y\\to \\mathbb {R} }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e2c7bc3330b76d58cdb3bff67e7b0ec60a2509c9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:15.102ex; height:2.509ex;" alt="{\\displaystyle f:X\\times Y\\to \\mathbb {R} }"/></span> such that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> is defined as returning the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span> value that gives the highest score: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g(x)={\\underset {y}{\\arg \\max }}\\;f(x,y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <munder>\n            <mrow>\n              <mi>arg</mi>\n              <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n              <mo movablelimits="true" form="prefix">max</mo>\n            </mrow>\n            <mi>y</mi>\n          </munder>\n        </mrow>\n        <mspace width="thickmathspace" />\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g(x)={\\underset {y}{\\arg \\max }}\\;f(x,y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/cba4bc7532dc87fa4312abad85326b21e99f96d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.671ex; width:22.555ex; height:4.676ex;" alt="{\\displaystyle g(x)={\\underset {y}{\\arg \\max }}\\;f(x,y)}"/></span>.  Let <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle F}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>F</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle F}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.741ex; height:2.176ex;" alt="F"/></span> denote the space of scoring functions.\n</p><p>Although <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle G}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>G</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle G}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.827ex; height:2.176ex;" alt="G"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle F}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>F</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle F}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/545fd099af8541605f7ee55f08225526be88ce57" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.741ex; height:2.176ex;" alt="F"/></span> can be any space of functions, many learning algorithms are probabilistic models where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> takes the form of a <a href="/wiki/Conditional_probability" title="Conditional probability">conditional probability</a> model <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g(x)=P(y|x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mi>P</mi>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g(x)=P(y|x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/82a1706f757c0414d749cef961f6a82975b963c5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:14.04ex; height:2.843ex;" alt="g(x) =&#10;P(y|x)"/></span>, or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> takes the form of a <a href="/wiki/Joint_probability" class="mw-redirect" title="Joint probability">joint probability</a> model <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f(x,y)=P(x,y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mi>P</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f(x,y)=P(x,y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/497c7a6614b31a86270a3a7bed89410bcd1e001c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:16.779ex; height:2.843ex;" alt="f(x,y) = P(x,y)"/></span>.  For example, <a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes</a> and <a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">linear discriminant analysis</a> are joint probability models, whereas <a href="/wiki/Logistic_regression" title="Logistic regression">logistic regression</a> is a conditional probability model.\n</p><p>There are two basic approaches to choosing <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span>: <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">empirical risk minimization</a> and <a href="/wiki/Structural_risk_minimization" title="Structural risk minimization">structural risk minimization</a>.<sup id="cite_ref-7" class="reference"><a href="#cite_note-7">&#91;7&#93;</a></sup>  Empirical risk minimization seeks the function that best fits the training data.  Structural risk minimization includes a <i>penalty function</i> that controls the bias/variance tradeoff.\n</p><p>In both cases, it is assumed that the training set consists of a sample of <a href="/wiki/Independent_and_identically-distributed_random_variables" class="mw-redirect" title="Independent and identically-distributed random variables">independent and identically distributed pairs</a>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle (x_{i},\\;y_{i})}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mspace width="thickmathspace" />\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle (x_{i},\\;y_{i})}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/413bed828a4750e458455095965e7082bece1e98" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.557ex; height:2.843ex;" alt="(x_i, \\;y_i)"/></span>.  In order to measure how well a function fits the training data, a <a href="/wiki/Loss_function" title="Loss function">loss function</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle L:Y\\times Y\\to \\mathbb {R} ^{\\geq 0}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>L</mi>\n        <mo>:</mo>\n        <mi>Y</mi>\n        <mo>&#x00D7;<!-- \xc3\x97 --></mo>\n        <mi>Y</mi>\n        <mo stretchy="false">&#x2192;<!-- \xe2\x86\x92 --></mo>\n        <msup>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi mathvariant="double-struck">R</mi>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo>&#x2265;<!-- \xe2\x89\xa5 --></mo>\n            <mn>0</mn>\n          </mrow>\n        </msup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle L:Y\\times Y\\to \\mathbb {R} ^{\\geq 0}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/881dc7b502a2b6a4970fb06609e170cf79475a59" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:17.532ex; height:2.676ex;" alt="{\\displaystyle L:Y\\times Y\\to \\mathbb {R} ^{\\geq 0}}"/></span> is defined.  For training example <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle (x_{i},\\;y_{i})}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mspace width="thickmathspace" />\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle (x_{i},\\;y_{i})}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/413bed828a4750e458455095965e7082bece1e98" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.557ex; height:2.843ex;" alt="(x_i,\\;y_i)"/></span>, the loss of predicting the value <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\hat {y}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>y</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\hat {y}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3dc8de3d8ea01304329ef9518fad7a6d196c4c01" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.302ex; height:2.509ex;" alt="{\\hat {y}}"/></span> is <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle L(y_{i},{\\hat {y}})}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>L</mi>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>y</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle L(y_{i},{\\hat {y}})}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6ac9025f28e57a00e0b20d64598436fe7a7477e9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:7.667ex; height:2.843ex;" alt="L(y_i,\\hat{y})"/></span>.\n</p><p>The <i>risk</i> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle R(g)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>R</mi>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle R(g)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ae075d527038ed7d449f85ced07e487b5807446c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.689ex; height:2.843ex;" alt="R(g)"/></span> of function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> is defined as the expected loss of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span>.  This can be estimated from the training data as\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle R_{emp}(g)={\\frac {1}{N}}\\sum _{i}L(y_{i},g(x_{i}))}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>R</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>e</mi>\n            <mi>m</mi>\n            <mi>p</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mfrac>\n            <mn>1</mn>\n            <mi>N</mi>\n          </mfrac>\n        </mrow>\n        <munder>\n          <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </munder>\n        <mi>L</mi>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mi>g</mi>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle R_{emp}(g)={\\frac {1}{N}}\\sum _{i}L(y_{i},g(x_{i}))}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87fa2fe2f731e8e1b02e2710d36fc16076e449bf" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:29.504ex; height:6.343ex;" alt="R_{emp}(g) = \\frac{1}{N} \\sum_i L(y_i, g(x_i))"/></span>.</dd></dl>\n<h3><span class="mw-headline" id="Empirical_risk_minimization">Empirical risk minimization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=10" title="Edit section: Empirical risk minimization">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></div>\n<p>In empirical risk minimization, the supervised learning algorithm seeks the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> that minimizes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle R(g)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>R</mi>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle R(g)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ae075d527038ed7d449f85ced07e487b5807446c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.689ex; height:2.843ex;" alt="R(g)"/></span>.  Hence, a supervised learning algorithm can be constructed by applying an <a href="/wiki/Optimization_(mathematics)" class="mw-redirect" title="Optimization (mathematics)">optimization algorithm</a> to find <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span>.\n</p><p>When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> is a conditional probability distribution <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle P(y|x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>P</mi>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle P(y|x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5d08508dff9e465cc317804ff19999c4ffbf7d94" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:6.687ex; height:2.843ex;" alt="P(y|x)"/></span> and the loss function is the negative log likelihood: <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle L(y,{\\hat {y}})=-\\log P(y|x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>L</mi>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mo>,</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mover>\n              <mi>y</mi>\n              <mo stretchy="false">&#x005E;<!-- ^ --></mo>\n            </mover>\n          </mrow>\n        </mrow>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>log</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mi>P</mi>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle L(y,{\\hat {y}})=-\\log P(y|x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/eaee3db78a569f2bb35e3dced4a1953ace44665b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:22.223ex; height:2.843ex;" alt="L(y, \\hat{y}) = -\\log P(y | x)"/></span>, then empirical risk minimization is equivalent to <a href="/wiki/Maximum_likelihood" class="mw-redirect" title="Maximum likelihood">maximum likelihood estimation</a>.\n</p><p>When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle G}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>G</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle G}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f5f3c8921a3b352de45446a6789b104458c9f90b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.827ex; height:2.176ex;" alt="G"/></span> contains many candidate functions or the training set is not sufficiently large, empirical risk minimization leads to high variance and poor generalization.  The learning algorithm is able\nto memorize the training examples without generalizing well.  This is called <a href="/wiki/Overfitting" title="Overfitting">overfitting</a>.\n</p>\n<h3><span class="mw-headline" id="Structural_risk_minimization">Structural risk minimization</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=11" title="Edit section: Structural risk minimization">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p><a href="/wiki/Structural_risk_minimization" title="Structural risk minimization">Structural risk minimization</a> seeks to prevent overfitting by incorporating a <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularization penalty</a> into the optimization.  The regularization penalty can be viewed as implementing a form of <a href="/wiki/Occam%27s_razor" title="Occam&#39;s razor">Occam\'s razor</a> that prefers simpler functions over more complex ones.\n</p><p>A wide variety of penalties have been employed that correspond to different definitions of complexity.  For example, consider the case where the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> is a linear function of the form\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g(x)=\\sum _{j=1}^{d}\\beta _{j}x_{j}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <munderover>\n          <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n            <mo>=</mo>\n            <mn>1</mn>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>d</mi>\n          </mrow>\n        </munderover>\n        <msub>\n          <mi>&#x03B2;<!-- \xce\xb2 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n          </mrow>\n        </msub>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g(x)=\\sum _{j=1}^{d}\\beta _{j}x_{j}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/86f23781682d33c596d0cda976b013e2b6fdf939" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:15.56ex; height:7.676ex;" alt=" g(x) = \\sum_{j=1}^d \\beta_j x_j"/></span>.</dd></dl>\n<p>A popular regularization penalty is <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\sum _{j}\\beta _{j}^{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <munder>\n          <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n          </mrow>\n        </munder>\n        <msubsup>\n          <mi>&#x03B2;<!-- \xce\xb2 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msubsup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\sum _{j}\\beta _{j}^{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f7df304919e1cdf3dfc49b9db648afce80a189ce" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:6.133ex; height:5.843ex;" alt="\\sum_j \\beta_j^2"/></span>, which is the squared <a href="/wiki/Euclidean_norm" class="mw-redirect" title="Euclidean norm">Euclidean norm</a> of the weights, also known as the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle L_{2}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>L</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>2</mn>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle L_{2}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c6a952cfe42c86b7741f55a817da0e251793a358" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.637ex; height:2.509ex;" alt="L_{2}"/></span> norm.  Other norms include the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle L_{1}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>L</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle L_{1}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0e79dc1b001f8b923df475ed14de023cbc456013" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.637ex; height:2.509ex;" alt="L_{1}"/></span> norm, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\sum _{j}|\\beta _{j}|}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <munder>\n          <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n          </mrow>\n        </munder>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <msub>\n          <mi>&#x03B2;<!-- \xce\xb2 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n          </mrow>\n        </msub>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\sum _{j}|\\beta _{j}|}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4f7c345923255a0cf76b3e2080b915eeb02f4126" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:7.261ex; height:5.843ex;" alt="\\sum_j |\\beta_j|"/></span>, and the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle L_{0}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>L</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>0</mn>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle L_{0}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/db742b8c210fc611329a4c2dcc3af4b4e1a110cb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.637ex; height:2.509ex;" alt="L_{0}"/></span> norm, which is the number of non-zero  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\beta _{j}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>&#x03B2;<!-- \xce\xb2 --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\beta _{j}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/83edf0558c67ad56ca5c05096b550bd733d62c4b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.225ex; height:2.843ex;" alt="\\beta _{j}"/></span>s.  The penalty will be denoted by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle C(g)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>C</mi>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle C(g)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e60538c5c17aadb0567923ff496ba4da02bcd40c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.692ex; height:2.843ex;" alt="C(g)"/></span>.\n</p><p>The supervised learning optimization problem is to find the function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> that minimizes\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle J(g)=R_{emp}(g)+\\lambda C(g).}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>J</mi>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <msub>\n          <mi>R</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>e</mi>\n            <mi>m</mi>\n            <mi>p</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n        <mo>+</mo>\n        <mi>&#x03BB;<!-- \xce\xbb --></mi>\n        <mi>C</mi>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n        <mo>.</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle J(g)=R_{emp}(g)+\\lambda C(g).}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f66b4b813c97f6598ed08791352e014fc7e16514" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:24.987ex; height:3.009ex;" alt=" J(g) = R_{emp}(g) + \\lambda C(g)."/></span></dd></dl>\n<p>The parameter <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\lambda }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03BB;<!-- \xce\xbb --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\lambda }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;" alt="\\lambda "/></span> controls the bias-variance tradeoff.  When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\lambda =0}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03BB;<!-- \xce\xbb --></mi>\n        <mo>=</mo>\n        <mn>0</mn>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\lambda =0}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/00c4bba30544017fe76932de5a4e25adb5512d95" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:5.616ex; height:2.176ex;" alt="\\lambda =0"/></span>, this gives empirical risk minimization with low bias and high variance.  When <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\lambda }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03BB;<!-- \xce\xbb --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\lambda }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;" alt="\\lambda "/></span> is large, the learning algorithm will have high bias and low variance.  The value of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\lambda }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03BB;<!-- \xce\xbb --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\lambda }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;" alt="\\lambda "/></span> can be chosen empirically via <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross validation</a>.\n</p><p>The complexity penalty has a Bayesian interpretation as the negative log prior probability of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle -\\log P(g)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>log</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mi>P</mi>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle -\\log P(g)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/140f8e655a53130f7068d9341b32891142e3a80c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.225ex; height:2.843ex;" alt="-\\log P(g)"/></span>, in which case <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle J(g)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>J</mi>\n        <mo stretchy="false">(</mo>\n        <mi>g</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle J(g)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eae208007bd0ddec50b7f177e991b914a11508" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.397ex; height:2.843ex;" alt="J(g)"/></span> is the <a href="/wiki/Posterior_probability" title="Posterior probability">posterior probabability</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span>.\n</p>\n<h2><span class="mw-headline" id="Generative_training">Generative training</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=12" title="Edit section: Generative training">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The training methods described above are <i>discriminative training</i> methods, because they seek to find a function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle g}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>g</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle g}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.116ex; height:2.009ex;" alt="g"/></span> that discriminates well between the different output values (see <a href="/wiki/Discriminative_model" title="Discriminative model">discriminative model</a>).  For the special case where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f(x,y)=P(x,y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mi>P</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f(x,y)=P(x,y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/497c7a6614b31a86270a3a7bed89410bcd1e001c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:16.779ex; height:2.843ex;" alt="f(x,y) = P(x,y)"/></span> is a <a href="/wiki/Joint_probability_distribution" title="Joint probability distribution">joint probability distribution</a> and the loss function is the negative log likelihood <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle -\\sum _{i}\\log P(x_{i},y_{i}),}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <munder>\n          <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </munder>\n        <mi>log</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mi>P</mi>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo>,</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle -\\sum _{i}\\log P(x_{i},y_{i}),}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/89be2acbbec6725f4ac254167f2d9cd7e97d2c7c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:18.6ex; height:5.509ex;" alt="- \\sum_i \\log P(x_i, y_i),"/></span> a risk minimization algorithm is said to perform <i>generative training</i>, because <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>f</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span> can be regarded as a <a href="/wiki/Generative_model" title="Generative model">generative model</a> that explains how the data were generated.  Generative training algorithms are often simpler and more computationally efficient than discriminative training algorithms.  In some cases, the solution can be computed in closed form as in <a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes</a> and <a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">linear discriminant analysis</a>.\n</p>\n<h2><span class="mw-headline" id="Generalizations">Generalizations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=13" title="Edit section: Generalizations">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>There are several ways in which the standard supervised learning problem can be generalized:\n</p>\n<ul><li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a>: In this setting, the desired output values are provided only for a subset of the training data.  The remaining data is unlabeled.</li>\n<li><a href="/wiki/Weak_supervision" title="Weak supervision">Weak supervision</a>: In this setting, noisy, limited, or imprecise sources are used to provide supervision signal for labeling training data.</li>\n<li><a href="/wiki/Active_learning_(machine_learning)" title="Active learning (machine learning)">Active learning</a>: Instead of assuming that all of the training examples are given at the start, active learning algorithms interactively collect new examples, typically by making queries to a human user.  Often, the queries are based on unlabeled data, which is a scenario that combines semi-supervised learning with active learning.</li>\n<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a>: When the desired output value is a complex object, such as a parse tree or a labeled graph, then standard methods must be extended.</li>\n<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a>: When the input is a set of objects and the desired output is a ranking of those objects, then again the standard methods must be extended.</li></ul>\n<h2><span class="mw-headline" id="Approaches_and_algorithms">Approaches and algorithms</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=14" title="Edit section: Approaches and algorithms">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li>Analytical learning</li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></li>\n<li><a href="/wiki/Backpropagation" title="Backpropagation">Backpropagation</a></li>\n<li><a href="/wiki/Boosting_(meta-algorithm)" class="mw-redirect" title="Boosting (meta-algorithm)">Boosting (meta-algorithm)</a></li>\n<li><a href="/wiki/Bayesian_statistics" title="Bayesian statistics">Bayesian statistics</a></li>\n<li><a href="/wiki/Case-based_reasoning" title="Case-based reasoning">Case-based reasoning</a></li>\n<li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision tree learning</a></li>\n<li><a href="/wiki/Inductive_logic_programming" title="Inductive logic programming">Inductive logic programming</a></li>\n<li><a href="/wiki/Gaussian_process_regression" class="mw-redirect" title="Gaussian process regression">Gaussian process regression</a></li>\n<li><a href="/wiki/Genetic_Programming" class="mw-redirect" title="Genetic Programming">Genetic Programming</a></li>\n<li><a href="/wiki/Group_method_of_data_handling" title="Group method of data handling">Group method of data handling</a></li>\n<li><a href="/wiki/Variable_kernel_density_estimation#Use_for_statistical_classification" title="Variable kernel density estimation">Kernel estimators</a></li>\n<li><a href="/wiki/Learning_Automata" class="mw-redirect" title="Learning Automata">Learning Automata</a></li>\n<li><a href="/wiki/Learning_classifier_system" title="Learning classifier system">Learning Classifier Systems</a></li>\n<li><a href="/wiki/Minimum_message_length" title="Minimum message length">Minimum message length</a> (<a href="/wiki/Decision_tree" title="Decision tree">decision trees</a>, decision graphs, etc.)</li>\n<li><a href="/wiki/Multilinear_subspace_learning" title="Multilinear subspace learning">Multilinear subspace learning</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes classifier</a></li>\n<li><a href="/wiki/Maximum_entropy_classifier" class="mw-redirect" title="Maximum entropy classifier">Maximum entropy classifier</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Nearest_neighbor_(pattern_recognition)" class="mw-redirect" title="Nearest neighbor (pattern recognition)">Nearest Neighbor Algorithm</a></li>\n<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">Probably approximately correct learning</a> (PAC) learning</li>\n<li><a href="/wiki/Ripple_down_rules" class="mw-redirect" title="Ripple down rules">Ripple down rules</a>, a knowledge acquisition methodology</li>\n<li>Symbolic machine learning algorithms</li>\n<li>Subsymbolic machine learning algorithms</li>\n<li><a href="/wiki/Support_vector_machine" class="mw-redirect" title="Support vector machine">Support vector machines</a></li>\n<li>Minimum Complexity Machines (MCM)</li>\n<li><a href="/wiki/Random_forest" title="Random forest">Random Forests</a></li>\n<li><a href="/wiki/Ensembles_of_Classifiers" class="mw-redirect" title="Ensembles of Classifiers">Ensembles of Classifiers</a></li>\n<li><a href="/wiki/Ordinal_classification" class="mw-redirect" title="Ordinal classification">Ordinal classification</a></li>\n<li><a href="/wiki/Data_Pre-processing" class="mw-redirect" title="Data Pre-processing">Data Pre-processing</a></li>\n<li>Handling imbalanced datasets</li>\n<li><a href="/wiki/Statistical_relational_learning" title="Statistical relational learning">Statistical relational learning</a></li>\n<li><a href="/wiki/Proaftn" title="Proaftn">Proaftn</a>, a multicriteria classification algorithm</li></ul>\n<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=15" title="Edit section: Applications">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a href="/wiki/Bioinformatics" title="Bioinformatics">Bioinformatics</a></li>\n<li><a href="/wiki/Cheminformatics" title="Cheminformatics">Cheminformatics</a>\n<ul><li><a href="/wiki/Quantitative_structure%E2%80%93activity_relationship" title="Quantitative structure\xe2\x80\x93activity relationship">Quantitative structure\xe2\x80\x93activity relationship</a></li></ul></li>\n<li><a href="/wiki/Database_marketing" title="Database marketing">Database marketing</a></li>\n<li><a href="/wiki/Handwriting_recognition" title="Handwriting recognition">Handwriting recognition</a></li>\n<li><a href="/wiki/Information_retrieval" title="Information retrieval">Information retrieval</a>\n<ul><li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li></ul></li>\n<li><a href="/wiki/Information_extraction" title="Information extraction">Information extraction</a></li>\n<li>Object recognition in <a href="/wiki/Computer_vision" title="Computer vision">computer vision</a></li>\n<li><a href="/wiki/Optical_character_recognition" title="Optical character recognition">Optical character recognition</a></li>\n<li><a href="/wiki/Spamming" title="Spamming">Spam detection</a></li>\n<li><a href="/wiki/Pattern_recognition" title="Pattern recognition">Pattern recognition</a></li>\n<li><a href="/wiki/Speech_recognition" title="Speech recognition">Speech recognition</a></li>\n<li>Supervised learning is a special case of <a href="/wiki/Downward_causation" title="Downward causation">Downward causation</a> in biological systems</li></ul>\n<h2><span class="mw-headline" id="General_issues">General issues</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=16" title="Edit section: General issues">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>\n<li><a href="/wiki/Inductive_bias" title="Inductive bias">Inductive bias</a></li>\n<li><a href="/wiki/Overfitting_(machine_learning)" class="mw-redirect" title="Overfitting (machine learning)">Overfitting (machine learning)</a></li>\n<li>(Uncalibrated) <a href="/wiki/Class_membership_probabilities" class="mw-redirect" title="Class membership probabilities">Class membership probabilities</a></li>\n<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>\n<li><a href="/wiki/Version_space" class="mw-redirect" title="Version space">Version spaces</a></li></ul>\n<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=17" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a href="/wiki/List_of_datasets_for_machine_learning_research" class="mw-redirect" title="List of datasets for machine learning research">List of datasets for machine learning research</a></li></ul>\n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=18" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="reflist" style="list-style-type: decimal;">\n<div class="mw-references-wrap"><ol class="references">\n<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text">Stuart J. Russell, Peter Norvig (2010) <i><a href="/wiki/Artificial_Intelligence:_A_Modern_Approach" title="Artificial Intelligence: A Modern Approach">Artificial Intelligence: A Modern Approach</a>, Third Edition</i>, Prentice Hall <style data-mw-deduplicate="TemplateStyles:r886058088">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\\"""\\"""\'""\'"}.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9780136042594" title="Special:BookSources/9780136042594">9780136042594</a>.</span>\n</li>\n<li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><a href="/wiki/Mehryar_Mohri" title="Mehryar Mohri">Mehryar Mohri</a>, Afshin Rostamizadeh, Ameet Talwalkar (2012) <i>Foundations of Machine Learning</i>, The MIT Press <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9780262018258" title="Special:BookSources/9780262018258">9780262018258</a>.</span>\n</li>\n<li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text">S. Geman, E. Bienenstock, and R. Doursat (1992). <a rel="nofollow" class="external text" href="http://delta-apache-vm.cs.tau.ac.il/~nin/Courses/NC06/VarbiasBiasGeman.pdf">Neural networks and the bias/variance dilemma</a>. Neural Computation 4, 1\xe2\x80\x9358.</span>\n</li>\n<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">G. James (2003) Variance and Bias for General Loss Functions,  Machine Learning 51, 115-135. (<a rel="nofollow" class="external free" href="http://www-bcf.usc.edu/~gareth/research/bv.pdf">http://www-bcf.usc.edu/~gareth/research/bv.pdf</a>)</span>\n</li>\n<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text">C.E. Brodely and M.A. Friedl (1999). Identifying and Eliminating Mislabeled Training Instances,  Journal of Artificial Intelligence Research 11, 131-167. (<a rel="nofollow" class="external free" href="http://jair.org/media/606/live-606-1803-jair.pdf">http://jair.org/media/606/live-606-1803-jair.pdf</a>)</span>\n</li>\n<li id="cite_note-6"><span class="mw-cite-backlink"><b><a href="#cite_ref-6">^</a></b></span> <span class="reference-text"><cite class="citation conference">M.R. Smith and T. Martinez (2011). "Improving Classification Accuracy by Identifying and Removing Instances that Should Be Misclassified". <i>Proceedings of International Joint Conference on Neural Networks (IJCNN 2011)</i>. pp.&#160;2690\xe2\x80\x932697. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.221.1371">10.1.1.221.1371</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1109%2FIJCNN.2011.6033571">10.1109/IJCNN.2011.6033571</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Improving+Classification+Accuracy+by+Identifying+and+Removing+Instances+that+Should+Be+Misclassified&amp;rft.btitle=Proceedings+of+International+Joint+Conference+on+Neural+Networks+%28IJCNN+2011%29&amp;rft.pages=2690-2697&amp;rft.date=2011&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.221.1371&amp;rft_id=info%3Adoi%2F10.1109%2FIJCNN.2011.6033571&amp;rft.au=M.R.+Smith+and+T.+Martinez&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASupervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-7">^</a></b></span> <span class="reference-text">Vapnik, V. N. <a rel="nofollow" class="external text" href="https://books.google.com/books?id=EqgACAAAQBAJ&amp;printsec=frontcover#v=snippet&amp;q=%22empirical%20risk%20minimization%22%20OR%20%22structural%20risk%20minimization%22&amp;f=false">The Nature of Statistical Learning Theory</a> (2nd Ed.), Springer Verlag, 2000.</span>\n</li>\n</ol></div></div>\n<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Supervised_learning&amp;action=edit&amp;section=19" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a rel="nofollow" class="external text" href="http://www.mloss.org/">Machine Learning Open Source Software (MLOSS)</a></li></ul>\n<!-- \nNewPP limit report\nParsed by mw1261\nCached time: 20191027021957\nCache expiry: 2592000\nDynamic content: false\nComplications: [vary\xe2\x80\x90revision\xe2\x80\x90sha1]\nCPU time usage: 0.348 seconds\nReal time usage: 0.569 seconds\nPreprocessor visited node count: 1260/1000000\nPreprocessor generated node count: 0/1500000\nPost\xe2\x80\x90expand include size: 31561/2097152 bytes\nTemplate argument size: 1710/2097152 bytes\nHighest expansion depth: 15/40\nExpensive parser function count: 2/500\nUnstrip recursion depth: 1/20\nUnstrip post\xe2\x80\x90expand size: 12692/5000000 bytes\nNumber of Wikibase entities loaded: 2/400\nLua time usage: 0.083/10.000 seconds\nLua memory usage: 2.37 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  359.875      1 -total\n 60.16%  216.498      1 Template:Reflist\n 33.96%  122.218      1 Template:Cite_conference\n 20.94%   75.373      2 Template:ISBN\n 18.18%   65.420      1 Template:See_also\n 13.60%   48.948      2 Template:Catalog_lookup_link\n 13.33%   47.987      1 Template:Machine_learning_bar\n 12.44%   44.764      1 Template:Sidebar_with_collapsible_lists\n  4.50%   16.193      1 Template:Longitem\n  3.79%   13.649      1 Template:Nobold\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:20926-0!canonical!math=5 and timestamp 20191027021956 and revision id 920525193\n -->\n</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>\n\t\t\n\t\t<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Supervised_learning&amp;oldid=920525193">https://en.wikipedia.org/w/index.php?title=Supervised_learning&amp;oldid=920525193</a>"</div>\n\t\t\n\t\t<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Supervised_learning" title="Category:Supervised learning">Supervised learning</a></li></ul></div></div>\n\t\t<div class="visualClear"></div>\n\t\t\n\t</div>\n</div>\n<div id=\'mw-data-after-content\'>\n\t<div class="read-more-container"></div>\n</div>\n\n\n\t\t<div id="mw-navigation">\n\t\t\t<h2>Navigation menu</h2>\n\t\t\t<div id="mw-head">\n\t\t\t\t\t\t\t\t\t<div id="p-personal" role="navigation" aria-labelledby="p-personal-label">\n\t\t\t\t\t\t<h3 id="p-personal-label">Personal tools</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Supervised+learning" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Supervised+learning" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t<div id="left-navigation">\n\t\t\t\t\t\t\t\t\t\t<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">\n\t\t\t\t\t\t<h3 id="p-namespaces-label">Namespaces</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="ca-nstab-main" class="selected"><span><a href="/wiki/Supervised_learning" title="View the content page [c]" accesskey="c">Article</a></span></li><li id="ca-talk"><span><a href="/wiki/Talk:Supervised_learning" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></span></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">\n\t\t\t\t\t\t\t\t\t\t\t\t<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />\n\t\t\t\t\t\t<h3 id="p-variants-label">\n\t\t\t\t\t\t\t<span>Variants</span>\n\t\t\t\t\t\t</h3>\n\t\t\t\t\t\t<ul class="menu">\n\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t<div id="right-navigation">\n\t\t\t\t\t\t\t\t\t\t<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">\n\t\t\t\t\t\t<h3 id="p-views-label">Views</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="ca-view" class="collapsible selected"><span><a href="/wiki/Supervised_learning">Read</a></span></li><li id="ca-edit" class="collapsible"><span><a href="/w/index.php?title=Supervised_learning&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></span></li><li id="ca-history" class="collapsible"><span><a href="/w/index.php?title=Supervised_learning&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></span></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">\n\t\t\t\t\t\t<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />\n\t\t\t\t\t\t<h3 id="p-cactions-label"><span>More</span></h3>\n\t\t\t\t\t\t<ul class="menu">\n\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-search" role="search">\n\t\t\t\t\t\t<h3>\n\t\t\t\t\t\t\t<label for="searchInput">Search</label>\n\t\t\t\t\t\t</h3>\n\t\t\t\t\t\t<form action="/w/index.php" id="searchform">\n\t\t\t\t\t\t\t<div id="simpleSearch">\n\t\t\t\t\t\t\t\t<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</form>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t<div id="mw-panel">\n\t\t\t\t<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a></div>\n\t\t\t\t\t\t<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">\n\t\t\t<h3 id="p-navigation-label">Navigation</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content \xe2\x80\x93 the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-interaction" aria-labelledby="p-interaction-label">\n\t\t\t<h3 id="p-interaction-label">Interaction</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">\n\t\t\t<h3 id="p-tb-label">Tools</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Supervised_learning" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Supervised_learning" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Supervised_learning&amp;oldid=920525193" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Supervised_learning&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q334384" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Supervised_learning&amp;id=920525193" title="Information on how to cite this page">Cite this page</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">\n\t\t\t<h3 id="p-coll-print_export-label">Print/export</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Supervised+learning">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Supervised+learning&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Supervised_learning&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label">\n\t\t\t<h3 id="p-lang-label">Languages</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li class="interlanguage-link interwiki-ar"><a href="https://ar.wikipedia.org/wiki/%D8%AA%D8%B9%D9%84%D9%8A%D9%85_%D9%85%D8%B1%D8%A7%D9%82%D8%A8_(%D8%A8%D8%A7%D9%84%D8%A5%D8%B4%D8%B1%D8%A7%D9%81)" title="\xd8\xaa\xd8\xb9\xd9\x84\xd9\x8a\xd9\x85 \xd9\x85\xd8\xb1\xd8\xa7\xd9\x82\xd8\xa8 (\xd8\xa8\xd8\xa7\xd9\x84\xd8\xa5\xd8\xb4\xd8\xb1\xd8\xa7\xd9\x81) \xe2\x80\x93 Arabic" lang="ar" hreflang="ar" class="interlanguage-link-target">\xd8\xa7\xd9\x84\xd8\xb9\xd8\xb1\xd8\xa8\xd9\x8a\xd8\xa9</a></li><li class="interlanguage-link interwiki-bn"><a href="https://bn.wikipedia.org/wiki/%E0%A6%A4%E0%A6%A4%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%AC%E0%A6%BE%E0%A6%AC%E0%A6%A7%E0%A6%BE%E0%A6%A8%E0%A7%87_%E0%A6%9C%E0%A7%8D%E0%A6%9E%E0%A6%BE%E0%A6%A8%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%9C%E0%A6%A8" title="\xe0\xa6\xa4\xe0\xa6\xa4\xe0\xa7\x8d\xe0\xa6\xa4\xe0\xa7\x8d\xe0\xa6\xac\xe0\xa6\xbe\xe0\xa6\xac\xe0\xa6\xa7\xe0\xa6\xbe\xe0\xa6\xa8\xe0\xa7\x87 \xe0\xa6\x9c\xe0\xa7\x8d\xe0\xa6\x9e\xe0\xa6\xbe\xe0\xa6\xa8\xe0\xa6\xbe\xe0\xa6\xb0\xe0\xa7\x8d\xe0\xa6\x9c\xe0\xa6\xa8 \xe2\x80\x93 Bangla" lang="bn" hreflang="bn" class="interlanguage-link-target">\xe0\xa6\xac\xe0\xa6\xbe\xe0\xa6\x82\xe0\xa6\xb2\xe0\xa6\xbe</a></li><li class="interlanguage-link interwiki-zh-min-nan"><a href="https://zh-min-nan.wikipedia.org/wiki/K%C3%A0m-tok_ha%CC%8Dk-si%CC%8Dp" title="K\xc3\xa0m-tok ha\xcc\x8dk-si\xcc\x8dp \xe2\x80\x93 Chinese (Min Nan)" lang="nan" hreflang="nan" class="interlanguage-link-target">B\xc3\xa2n-l\xc3\xa2m-g\xc3\xba</a></li><li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Aprenentatge_supervisat" title="Aprenentatge supervisat \xe2\x80\x93 Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Catal\xc3\xa0</a></li><li class="interlanguage-link interwiki-cs"><a href="https://cs.wikipedia.org/wiki/U%C4%8Den%C3%AD_s_u%C4%8Ditelem" title="U\xc4\x8den\xc3\xad s u\xc4\x8ditelem \xe2\x80\x93 Czech" lang="cs" hreflang="cs" class="interlanguage-link-target">\xc4\x8ce\xc5\xa1tina</a></li><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/%C3%9Cberwachtes_Lernen" title="\xc3\x9cberwachtes Lernen \xe2\x80\x93 German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-el"><a href="https://el.wikipedia.org/wiki/%CE%95%CF%80%CE%B9%CE%B2%CE%BB%CE%B5%CF%80%CF%8C%CE%BC%CE%B5%CE%BD%CE%B7_%CE%BC%CE%AC%CE%B8%CE%B7%CF%83%CE%B7" title="\xce\x95\xcf\x80\xce\xb9\xce\xb2\xce\xbb\xce\xb5\xcf\x80\xcf\x8c\xce\xbc\xce\xb5\xce\xbd\xce\xb7 \xce\xbc\xce\xac\xce\xb8\xce\xb7\xcf\x83\xce\xb7 \xe2\x80\x93 Greek" lang="el" hreflang="el" class="interlanguage-link-target">\xce\x95\xce\xbb\xce\xbb\xce\xb7\xce\xbd\xce\xb9\xce\xba\xce\xac</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Aprendizaje_supervisado" title="Aprendizaje supervisado \xe2\x80\x93 Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Espa\xc3\xb1ol</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%DB%8C%D8%A7%D8%AF%DA%AF%DB%8C%D8%B1%DB%8C_%D8%A8%D8%A7_%D9%86%D8%B8%D8%A7%D8%B1%D8%AA" title="\xdb\x8c\xd8\xa7\xd8\xaf\xda\xaf\xdb\x8c\xd8\xb1\xdb\x8c \xd8\xa8\xd8\xa7 \xd9\x86\xd8\xb8\xd8\xa7\xd8\xb1\xd8\xaa \xe2\x80\x93 Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">\xd9\x81\xd8\xa7\xd8\xb1\xd8\xb3\xdb\x8c</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Apprentissage_supervis%C3%A9" title="Apprentissage supervis\xc3\xa9 \xe2\x80\x93 French" lang="fr" hreflang="fr" class="interlanguage-link-target">Fran\xc3\xa7ais</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EC%A7%80%EB%8F%84_%ED%95%99%EC%8A%B5" title="\xec\xa7\x80\xeb\x8f\x84 \xed\x95\x99\xec\x8a\xb5 \xe2\x80\x93 Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">\xed\x95\x9c\xea\xb5\xad\xec\x96\xb4</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Apprendimento_supervisionato" title="Apprendimento supervisionato \xe2\x80\x93 Italian" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-he"><a href="https://he.wikipedia.org/wiki/%D7%9C%D7%9E%D7%99%D7%93%D7%94_%D7%9E%D7%95%D7%A0%D7%97%D7%99%D7%AA" title="\xd7\x9c\xd7\x9e\xd7\x99\xd7\x93\xd7\x94 \xd7\x9e\xd7\x95\xd7\xa0\xd7\x97\xd7\x99\xd7\xaa \xe2\x80\x93 Hebrew" lang="he" hreflang="he" class="interlanguage-link-target">\xd7\xa2\xd7\x91\xd7\xa8\xd7\x99\xd7\xaa</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E6%95%99%E5%B8%AB%E3%81%82%E3%82%8A%E5%AD%A6%E7%BF%92" title="\xe6\x95\x99\xe5\xb8\xab\xe3\x81\x82\xe3\x82\x8a\xe5\xad\xa6\xe7\xbf\x92 \xe2\x80\x93 Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">\xe6\x97\xa5\xe6\x9c\xac\xe8\xaa\x9e</a></li><li class="interlanguage-link interwiki-or"><a href="https://or.wikipedia.org/wiki/%E0%AC%B8%E0%AD%81%E0%AC%AA%E0%AC%B0%E0%AC%AD%E0%AC%BE%E0%AC%87%E0%AC%9C%E0%AC%A1_%E0%AC%B2%E0%AC%B0%E0%AD%8D%E0%AC%A3%E0%AC%BF%E0%AC%82" title="\xe0\xac\xb8\xe0\xad\x81\xe0\xac\xaa\xe0\xac\xb0\xe0\xac\xad\xe0\xac\xbe\xe0\xac\x87\xe0\xac\x9c\xe0\xac\xa1 \xe0\xac\xb2\xe0\xac\xb0\xe0\xad\x8d\xe0\xac\xa3\xe0\xac\xbf\xe0\xac\x82 \xe2\x80\x93 Odia" lang="or" hreflang="or" class="interlanguage-link-target">\xe0\xac\x93\xe0\xac\xa1\xe0\xac\xbc\xe0\xac\xbf\xe0\xac\x86</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Uczenie_nadzorowane" title="Uczenie nadzorowane \xe2\x80\x93 Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%BC" title="\xd0\x9e\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5 \xd1\x81 \xd1\x83\xd1\x87\xd0\xb8\xd1\x82\xd0\xb5\xd0\xbb\xd0\xb5\xd0\xbc \xe2\x80\x93 Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">\xd0\xa0\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9</a></li><li class="interlanguage-link interwiki-simple"><a href="https://simple.wikipedia.org/wiki/Supervised_learning" title="Supervised learning \xe2\x80\x93 Simple English" lang="en-simple" hreflang="en-simple" class="interlanguage-link-target">Simple English</a></li><li class="interlanguage-link interwiki-ckb"><a href="https://ckb.wikipedia.org/wiki/%D9%81%DB%8E%D8%B1%D8%A8%D9%88%D9%88%D9%86%DB%8C_%DA%86%D8%A7%D9%88%D8%AF%DB%8E%D8%B1%DB%8C%DA%A9%D8%B1%D8%A7%D9%88" title="\xd9\x81\xdb\x8e\xd8\xb1\xd8\xa8\xd9\x88\xd9\x88\xd9\x86\xdb\x8c \xda\x86\xd8\xa7\xd9\x88\xd8\xaf\xdb\x8e\xd8\xb1\xdb\x8c\xda\xa9\xd8\xb1\xd8\xa7\xd9\x88 \xe2\x80\x93 Central Kurdish" lang="ckb" hreflang="ckb" class="interlanguage-link-target">\xda\xa9\xd9\x88\xd8\xb1\xd8\xaf\xdb\x8c</a></li><li class="interlanguage-link interwiki-fi"><a href="https://fi.wikipedia.org/wiki/Ohjattu_oppiminen" title="Ohjattu oppiminen \xe2\x80\x93 Finnish" lang="fi" hreflang="fi" class="interlanguage-link-target">Suomi</a></li><li class="interlanguage-link interwiki-th"><a href="https://th.wikipedia.org/wiki/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B9%80%E0%B8%A3%E0%B8%B5%E0%B8%A2%E0%B8%99%E0%B8%A3%E0%B8%B9%E0%B9%89%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B8%A1%E0%B8%B5%E0%B8%9C%E0%B8%B9%E0%B9%89%E0%B8%AA%E0%B8%AD%E0%B8%99" title="\xe0\xb8\x81\xe0\xb8\xb2\xe0\xb8\xa3\xe0\xb9\x80\xe0\xb8\xa3\xe0\xb8\xb5\xe0\xb8\xa2\xe0\xb8\x99\xe0\xb8\xa3\xe0\xb8\xb9\xe0\xb9\x89\xe0\xb9\x81\xe0\xb8\x9a\xe0\xb8\x9a\xe0\xb8\xa1\xe0\xb8\xb5\xe0\xb8\x9c\xe0\xb8\xb9\xe0\xb9\x89\xe0\xb8\xaa\xe0\xb8\xad\xe0\xb8\x99 \xe2\x80\x93 Thai" lang="th" hreflang="th" class="interlanguage-link-target">\xe0\xb9\x84\xe0\xb8\x97\xe0\xb8\xa2</a></li><li class="interlanguage-link interwiki-tr"><a href="https://tr.wikipedia.org/wiki/G%C3%B6zetimli_%C3%B6%C4%9Frenme" title="G\xc3\xb6zetimli \xc3\xb6\xc4\x9frenme \xe2\x80\x93 Turkish" lang="tr" hreflang="tr" class="interlanguage-link-target">T\xc3\xbcrk\xc3\xa7e</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F_%D0%B7_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D0%B5%D0%BC" title="\xd0\x9d\xd0\xb0\xd0\xb2\xd1\x87\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8f \xd0\xb7 \xd1\x83\xd1\x87\xd0\xb8\xd1\x82\xd0\xb5\xd0\xbb\xd0\xb5\xd0\xbc \xe2\x80\x93 Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">\xd0\xa3\xd0\xba\xd1\x80\xd0\xb0\xd1\x97\xd0\xbd\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0</a></li><li class="interlanguage-link interwiki-vi"><a href="https://vi.wikipedia.org/wiki/H%E1%BB%8Dc_c%C3%B3_gi%C3%A1m_s%C3%A1t" title="H\xe1\xbb\x8dc c\xc3\xb3 gi\xc3\xa1m s\xc3\xa1t \xe2\x80\x93 Vietnamese" lang="vi" hreflang="vi" class="interlanguage-link-target">Ti\xe1\xba\xbfng Vi\xe1\xbb\x87t</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E7%9B%A3%E7%9D%A3%E5%BC%8F%E5%AD%B8%E7%BF%92" title="\xe7\x9b\xa3\xe7\x9d\xa3\xe5\xbc\x8f\xe5\xad\xb8\xe7\xbf\x92 \xe2\x80\x93 Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">\xe4\xb8\xad\xe6\x96\x87</a></li>\t\t\t\t</ul>\n\t\t\t\t<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q334384#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>\t\t\t</div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t</div>\n\t\t\t\t<div id="footer" role="contentinfo">\n\t\t\t\t\t\t<ul id="footer-info">\n\t\t\t\t\t\t\t\t<li id="footer-info-lastmod"> This page was last edited on 10 October 2019, at 09:53<span class="anonymous-show">&#160;(UTC)</span>.</li>\n\t\t\t\t\t\t\t\t<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia\xc2\xae is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t<ul id="footer-places">\n\t\t\t\t\t\t\t\t<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Supervised_learning&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>\n\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t\t\t\t\t<ul id="footer-icons" class="noprint">\n\t\t\t\t\t\t\t\t\t\t<li id="footer-copyrightico">\n\t\t\t\t\t\t<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t<li id="footer-poweredbyico">\n\t\t\t\t\t\t<a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t<div style="clear: both;"></div>\n\t\t</div>\n\t\t\n\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.348","walltime":"0.569","ppvisitednodes":{"value":1260,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":31561,"limit":2097152},"templateargumentsize":{"value":1710,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":2,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":12692,"limit":5000000},"entityaccesscount":{"value":2,"limit":400},"timingprofile":["100.00%  359.875      1 -total"," 60.16%  216.498      1 Template:Reflist"," 33.96%  122.218      1 Template:Cite_conference"," 20.94%   75.373      2 Template:ISBN"," 18.18%   65.420      1 Template:See_also"," 13.60%   48.948      2 Template:Catalog_lookup_link"," 13.33%   47.987      1 Template:Machine_learning_bar"," 12.44%   44.764      1 Template:Sidebar_with_collapsible_lists","  4.50%   16.193      1 Template:Longitem","  3.79%   13.649      1 Template:Nobold"]},"scribunto":{"limitreport-timeusage":{"value":"0.083","limit":"10.000"},"limitreport-memusage":{"value":2483004,"limit":52428800}},"cachereport":{"origin":"mw1261","timestamp":"20191027021957","ttl":2592000,"transientcontent":false}}});});</script>\n<script type="application/ld+json">{"@context":"https:\\/\\/schema.org","@type":"Article","name":"Supervised learning","url":"https:\\/\\/en.wikipedia.org\\/wiki\\/Supervised_learning","sameAs":"http:\\/\\/www.wikidata.org\\/entity\\/Q334384","mainEntity":"http:\\/\\/www.wikidata.org\\/entity\\/Q334384","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png"}},"datePublished":"2002-01-08T05:43:27Z","dateModified":"2019-10-10T09:53:30Z","image":"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/f\\/fe\\/Kernel_Machine.svg","headline":"machine learning task of learning a function that maps an input to an output based on example input-output pairs"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":93,"wgHostname":"mw1267"});});</script>\n</body>\n</html>\n'