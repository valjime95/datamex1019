b'<!DOCTYPE html>\n<html class="client-nojs" lang="en" dir="ltr">\n<head>\n<meta charset="UTF-8"/>\n<title>Semi-supervised learning - Wikipedia</title>\n<script>document.documentElement.className="client-js";RLCONF={"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Semi-supervised_learning","wgTitle":"Semi-supervised learning","wgCurRevisionId":922225491,"wgRevisionId":922225491,"wgArticleId":2829632,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 errors: missing periodical","CS1 maint: multiple names: authors list","All accuracy disputes","Articles with disputed statements from November 2017","Machine learning"],"wgBreakFrames":!1,"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgMonthNamesShort":["","Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"],\n"wgRelevantPageName":"Semi-supervised_learning","wgRelevantArticleId":2829632,"wgRequestId":"XcN6UgpAMFIAAJsIK-oAAAAQ","wgCSPNonce":!1,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgWikibaseItemId":"Q1041418","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"ready","user.tokens":"loading",\n"ext.math.styles":"ready","ext.cite.styles":"ready","mediawiki.legacy.shared":"ready","mediawiki.legacy.commonPrint":"ready","mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","ext.3d.styles":"ready","mediawiki.skinning.interface":"ready","skins.vector.styles":"ready"};RLPAGEMODULES=["ext.math.scripts","ext.cite.ux-enhancements","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.toc","mediawiki.searchSuggest","ext.gadget.teahouse","ext.gadget.ReferenceTooltips","ext.gadget.watchlist-notice","ext.gadget.DRN-wizard","ext.gadget.charinsert","ext.gadget.refToolbar","ext.gadget.extra-toolbar-buttons","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming",\n"ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp","skins.vector.js"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.tokens@tffin",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\\\","watchToken":"+\\\\","csrfToken":"+\\\\"});\n});});</script>\n<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.3d.styles%7Cext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.legacy.commonPrint%2Cshared%7Cmediawiki.skinning.interface%7Cmediawiki.toc.styles%7Cskins.vector.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>\n<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>\n<meta name="ResourceLoaderDynamicStyles" content=""/>\n<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>\n<meta name="generator" content="MediaWiki 1.35.0-wmf.4"/>\n<meta name="referrer" content="origin"/>\n<meta name="referrer" content="origin-when-crossorigin"/>\n<meta name="referrer" content="origin-when-cross-origin"/>\n<meta property="og:image" content="https://upload.wikimedia.org/wikipedia/commons/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png"/>\n<link rel="alternate" href="android-app://org.wikipedia/http/en.m.wikipedia.org/wiki/Semi-supervised_learning"/>\n<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Semi-supervised_learning&amp;action=edit"/>\n<link rel="edit" title="Edit this page" href="/w/index.php?title=Semi-supervised_learning&amp;action=edit"/>\n<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>\n<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>\n<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>\n<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>\n<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>\n<link rel="canonical" href="https://en.wikipedia.org/wiki/Semi-supervised_learning"/>\n<link rel="dns-prefetch" href="//login.wikimedia.org"/>\n<link rel="dns-prefetch" href="//meta.wikimedia.org" />\n<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->\n</head>\n<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Semi-supervised_learning rootpage-Semi-supervised_learning skin-vector action-view">\n<div id="mw-page-base" class="noprint"></div>\n<div id="mw-head-base" class="noprint"></div>\n<div id="content" class="mw-body" role="main">\n\t<a id="top"></a>\n\t<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>\n\t<div class="mw-indicators mw-body-content">\n</div>\n\n\t<h1 id="firstHeading" class="firstHeading" lang="en">Semi-supervised learning</h1>\n\t\n\t<div id="bodyContent" class="mw-body-content">\n\t\t<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>\n\t\t<div id="contentSub"></div>\n\t\t\n\t\t\n\t\t\n\t\t<div id="jump-to-nav"></div>\n\t\t<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>\n\t\t<a class="mw-jump-link" href="#p-search">Jump to search</a>\n\t\t<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f9f9f9;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><th style="padding:0.2em 0.4em 0.2em;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a> and<br /><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0.2em 0 0.4em;padding:0.25em 0.25em 0.75em;"><a href="/wiki/File:Kernel_Machine.svg" class="image"><img alt="Kernel Machine.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/220px-Kernel_Machine.svg.png" decoding="async" width="220" height="100" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/330px-Kernel_Machine.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/440px-Kernel_Machine.svg.png 2x" data-file-width="512" data-file-height="233" /></a></td></tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>\n<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>\n<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>\n<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>\n<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>\n<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>\n<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>\n<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>\n<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>\n<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>\n<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>\n<li><a class="mw-selflink selflink">Semi-supervised learning</a></li>\n<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>\n<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>\n<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br /><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>&#160;&#8226;&#32;<b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>\n<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>\n<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>\n<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>\n<li><a href="/wiki/Random_forest" title="Random forest">Random forest</a></li></ul></li>\n<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>\n<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>\n<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>\n<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>\n<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>\n<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>\n<li><a href="/wiki/Support-vector_machine" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>\n<li><a href="/wiki/CURE_data_clustering_algorithm" class="mw-redirect" title="CURE data clustering algorithm">CURE</a></li>\n<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>\n<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>\n<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation\xe2\x80\x93maximization algorithm">Expectation\xe2\x80\x93maximization (EM)</a></li>\n<li><br /><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>\n<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>\n<li><a href="/wiki/Mean-shift" class="mw-redirect" title="Mean-shift">Mean-shift</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>\n<li><a href="/wiki/Canonical_correlation_analysis" class="mw-redirect" title="Canonical correlation analysis">CCA</a></li>\n<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>\n<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>\n<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>\n<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>\n<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>\n<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>\n<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>\n<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/K-nearest_neighbors_classification" class="mw-redirect" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>\n<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_networks" class="mw-redirect" title="Artificial neural networks">Artificial neural networks</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>\n<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>\n<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>\n<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>\n<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>\n<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>\n<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>\n<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>\n<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>\n<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>\n<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>\n<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>\n<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State\xe2\x80\x93action\xe2\x80\x93reward\xe2\x80\x93state\xe2\x80\x93action">SARSA</a></li>\n<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Bias%E2%80%93variance_dilemma" class="mw-redirect" title="Bias\xe2\x80\x93variance dilemma">Bias\xe2\x80\x93variance dilemma</a></li>\n<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>\n<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>\n<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>\n<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>\n<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>\n<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik\xe2\x80\x93Chervonenkis theory">VC theory</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NIPS</a></li>\n<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>\n<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>\n<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>\n<li><a rel="nofollow" class="external text" href="https://arxiv.org/list/cs.LG/recent">ArXiv:cs.LG</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="padding:0 0.1em 0.4em">\n<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">\n<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>\n<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>\n</div></div></div></td>\n</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>\n<div class="thumb tright"><div class="thumbinner" style="width:196px;"><a href="/wiki/File:Example_of_unlabeled_data_in_semisupervised_learning.png" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png/194px-Example_of_unlabeled_data_in_semisupervised_learning.png" decoding="async" width="194" height="225" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png/291px-Example_of_unlabeled_data_in_semisupervised_learning.png 1.5x, //upload.wikimedia.org/wikipedia/commons/d/d0/Example_of_unlabeled_data_in_semisupervised_learning.png 2x" data-file-width="388" data-file-height="449" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Example_of_unlabeled_data_in_semisupervised_learning.png" class="internal" title="Enlarge"></a></div>An example of the influence of unlabeled data in semi-supervised learning.  The top panel shows a decision boundary we might adopt after seeing only one positive (white circle) and one negative (black circle) example.  The bottom panel shows a decision boundary we might adopt if, in addition to the two labeled examples, we were given a collection of unlabeled data (gray circles).  This could be viewed as performing <a href="/wiki/Cluster_analysis" title="Cluster analysis">clustering</a> and then labeling the clusters with the labeled data, pushing the decision boundary away from high-density regions, or learning an underlying one-dimensional manifold where the data reside.</div></div></div>\n<p><b>Semi-supervised learning</b> is a class of <a href="/wiki/Machine_learning" title="Machine learning">machine learning</a> tasks and techniques that also make use of unlabeled <a href="/wiki/Data" title="Data">data</a> for training \xe2\x80\x93 typically a small amount of <a href="/wiki/Labeled_data" title="Labeled data">labeled data</a> with a large amount of unlabeled data.  Semi-supervised learning falls between <a href="/wiki/Unsupervised_learning" title="Unsupervised learning">unsupervised learning</a> (without any labeled training data) and <a href="/wiki/Supervised_learning" title="Supervised learning">supervised learning</a> (with completely labeled training data).  Many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy. The acquisition of labeled data for a learning problem often requires a skilled human agent (e.g. to transcribe an audio segment) or a physical experiment (e.g. determining the 3D structure of a protein or determining whether there is oil at a particular location). The cost associated with the labeling process thus may render a fully labeled training set infeasible, whereas acquisition of unlabeled data is relatively inexpensive. In such situations, semi-supervised learning can be of great practical value.  Semi-supervised learning is also of theoretical interest in machine learning and as a model for human learning.\n</p><p>As in the supervised learning framework, we are given a set of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle l}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>l</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle l}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/829091f745070b9eb97a80244129025440a1cfac" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.693ex; height:2.176ex;" alt="l"/></span> <a href="/wiki/Independent_identically_distributed" class="mw-redirect" title="Independent identically distributed">independently identically distributed</a> examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{1},\\dots ,x_{l}\\in X}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2208;<!-- \xe2\x88\x88 --></mo>\n        <mi>X</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{1},\\dots ,x_{l}\\in X}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/76da26bfd12e40809f4b2dae37ecca34ad1c825c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:14.435ex; height:2.509ex;" alt="x_{1},\\dots ,x_{l}\\in X"/></span> with corresponding labels <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y_{1},\\dots ,y_{l}\\in Y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mi>y</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2208;<!-- \xe2\x88\x88 --></mo>\n        <mi>Y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y_{1},\\dots ,y_{l}\\in Y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4b376abba952ea1dca784912adb9a3bfd006eb6b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:13.847ex; height:2.509ex;" alt="y_{1},\\dots ,y_{l}\\in Y"/></span>.  Additionally, we are given <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle u}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>u</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle u}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3e6bb763d22c20916ed4f0bb6bd49d7470cffd8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="u"/></span> unlabeled examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{l+1},\\dots ,x_{l+u}\\in X}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n            <mo>+</mo>\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n            <mo>+</mo>\n            <mi>u</mi>\n          </mrow>\n        </msub>\n        <mo>&#x2208;<!-- \xe2\x88\x88 --></mo>\n        <mi>X</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{l+1},\\dots ,x_{l+u}\\in X}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/60a05a61c90d36f1a9def946c7dd83e826162b26" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:18.423ex; height:2.509ex;" alt="x_{l+1},\\dots ,x_{l+u}\\in X"/></span>.  Semi-supervised learning attempts to make use of this combined information to surpass the <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a> performance that could be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning.\n</p><p>Semi-supervised learning may refer to either <a href="/wiki/Transduction_(machine_learning)" title="Transduction (machine learning)">transductive learning</a> or <a href="/wiki/Inductive_reasoning" title="Inductive reasoning">inductive learning</a><sup id="cite_ref-1" class="reference"><a href="#cite_note-1">&#91;1&#93;</a></sup>  The goal of transductive learning is to infer the correct labels for the given unlabeled data <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{l+1},\\dots ,x_{l+u}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n            <mo>+</mo>\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n            <mo>+</mo>\n            <mi>u</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{l+1},\\dots ,x_{l+u}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/76df04fc221300e6e1d6de65cf9d4f8614280ae6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:13.602ex; height:2.009ex;" alt="x_{l+1},\\dots ,x_{l+u}"/></span> only.  The goal of inductive learning is to infer the correct mapping from <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle X}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>X</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle X}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68baa052181f707c662844a465bfeeb135e82bab" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.98ex; height:2.176ex;" alt="X"/></span> to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle Y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>Y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle Y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"/></span>.\n</p><p>Intuitively, we can think of the learning problem as an exam and labeled data as the few example problems that the teacher solved in class.  The teacher also provides a set of unsolved problems.  In the transductive setting, these unsolved problems are a take-home exam and you want to do well on them in particular.  In the inductive setting, these are practice problems of the sort you will encounter on the in-class exam.\n</p><p>It is unnecessary (and, according to <a href="/wiki/Vapnik%27s_principle" class="mw-redirect" title="Vapnik&#39;s principle">Vapnik\'s principle</a>, imprudent) to perform transductive learning by way of inferring a classification rule over the entire input space; however, in practice, algorithms formally designed for transduction or induction are often used interchangeably.\n</p>\n<div id="toc" class="toc"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2>Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>\n<ul>\n<li class="toclevel-1 tocsection-1"><a href="#Assumptions_used"><span class="tocnumber">1</span> <span class="toctext">Assumptions used</span></a>\n<ul>\n<li class="toclevel-2 tocsection-2"><a href="#Continuity_assumption"><span class="tocnumber">1.1</span> <span class="toctext">Continuity assumption</span></a></li>\n<li class="toclevel-2 tocsection-3"><a href="#Cluster_assumption"><span class="tocnumber">1.2</span> <span class="toctext">Cluster assumption</span></a></li>\n<li class="toclevel-2 tocsection-4"><a href="#Manifold_assumption"><span class="tocnumber">1.3</span> <span class="toctext">Manifold assumption</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-5"><a href="#History"><span class="tocnumber">2</span> <span class="toctext">History</span></a></li>\n<li class="toclevel-1 tocsection-6"><a href="#Methods"><span class="tocnumber">3</span> <span class="toctext">Methods</span></a>\n<ul>\n<li class="toclevel-2 tocsection-7"><a href="#Generative_models"><span class="tocnumber">3.1</span> <span class="toctext">Generative models</span></a></li>\n<li class="toclevel-2 tocsection-8"><a href="#Low-density_separation"><span class="tocnumber">3.2</span> <span class="toctext">Low-density separation</span></a></li>\n<li class="toclevel-2 tocsection-9"><a href="#Graph-based_methods"><span class="tocnumber">3.3</span> <span class="toctext">Graph-based methods</span></a></li>\n<li class="toclevel-2 tocsection-10"><a href="#Heuristic_approaches"><span class="tocnumber">3.4</span> <span class="toctext">Heuristic approaches</span></a></li>\n</ul>\n</li>\n<li class="toclevel-1 tocsection-11"><a href="#In_human_cognition"><span class="tocnumber">4</span> <span class="toctext">In human cognition</span></a></li>\n<li class="toclevel-1 tocsection-12"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li>\n<li class="toclevel-1 tocsection-13"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li>\n<li class="toclevel-1 tocsection-14"><a href="#External_links"><span class="tocnumber">7</span> <span class="toctext">External links</span></a></li>\n</ul>\n</div>\n\n<h2><span class="mw-headline" id="Assumptions_used">Assumptions used</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=1" title="Edit section: Assumptions used">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>In order to make any use of unlabeled data, we must assume some structure to the underlying distribution of data.  Semi-supervised learning algorithms make use of at least one of the following assumptions.\n<sup id="cite_ref-Chapelle_2-0" class="reference"><a href="#cite_note-Chapelle-2">&#91;2&#93;</a></sup>\n</p>\n<h3><span class="mw-headline" id="Continuity_assumption">Continuity assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=2" title="Edit section: Continuity assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p><i>Points which are close to each other are more likely to share a label.</i> This is also generally assumed in supervised learning and yields a preference for geometrically simple <a href="/wiki/Decision_boundary" title="Decision boundary">decision boundaries</a>.  In the case of semi-supervised learning, the smoothness assumption additionally yields a preference for decision boundaries in low-density regions, so that there are fewer points close to each other but in different classes.\n</p>\n<h3><span class="mw-headline" id="Cluster_assumption">Cluster assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=3" title="Edit section: Cluster assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p><i>The data tend to form discrete clusters, and points in the same cluster are more likely to share a label</i> (although data sharing a label may be spread across multiple clusters).  This is a special case of the smoothness assumption and gives rise to <a href="/wiki/Feature_learning" title="Feature learning">feature learning</a> with clustering algorithms.\n</p>\n<h3><span class="mw-headline" id="Manifold_assumption">Manifold assumption</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=4" title="Edit section: Manifold assumption">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p><i>The data lie approximately on a <a href="/wiki/Manifold" title="Manifold">manifold</a> of much lower dimension than the input space.</i>  In this case we can attempt to learn the manifold using both the labeled and unlabeled data to avoid the <a href="/wiki/Curse_of_dimensionality" title="Curse of dimensionality">curse of dimensionality</a>.  Then learning can proceed using distances and densities defined on the manifold.\n</p><p>The manifold assumption is practical when high-dimensional data are being generated by some process that may be hard to model directly, but which only has a few degrees of freedom.  For instance, human voice is controlled by a few vocal folds,<sup id="cite_ref-StevensKN_3-0" class="reference"><a href="#cite_note-StevensKN-3">&#91;3&#93;</a></sup> and images of various facial expressions are controlled by a few muscles.  We would like in these cases to use distances and smoothness in the natural space of the generating problem, rather than in the space of all possible acoustic waves or images respectively.\n</p>\n<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=5" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>The heuristic approach of <i>self-training</i> (also known as <i>self-learning</i> or <i>self-labeling</i>) is historically the oldest approach to semi-supervised learning,<sup id="cite_ref-Chapelle_2-1" class="reference"><a href="#cite_note-Chapelle-2">&#91;2&#93;</a></sup> with examples of applications starting in the 1960s (see for instance Scudder (1965)<sup id="cite_ref-4" class="reference"><a href="#cite_note-4">&#91;4&#93;</a></sup>).\n</p><p>The transductive learning framework was formally introduced by <a href="/wiki/Vladimir_Vapnik" title="Vladimir Vapnik">Vladimir Vapnik</a> in the 1970s.<sup id="cite_ref-5" class="reference"><a href="#cite_note-5">&#91;5&#93;</a></sup> Interest in inductive learning using generative models also began in the 1970s.  A <a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning"><i>probably approximately correct</i> learning</a> bound for semi-supervised learning of a Gaussian mixture was demonstrated by Ratsaby and Venkatesh in 1995.<sup id="cite_ref-Ratsaby_6-0" class="reference"><a href="#cite_note-Ratsaby-6">&#91;6&#93;</a></sup>\n</p><p>Semi-supervised learning has recently become more popular and practically relevant due to the variety of problems for which vast quantities of unlabeled data are available\xe2\x80\x94e.g. text on websites, protein sequences, or images.  For a review of recent work see a survey article by Zhu (2008).<sup id="cite_ref-survey_7-0" class="reference"><a href="#cite_note-survey-7">&#91;7&#93;</a></sup>\n</p>\n<h2><span class="mw-headline" id="Methods">Methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=6" title="Edit section: Methods">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<h3><span class="mw-headline" id="Generative_models">Generative models</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=7" title="Edit section: Generative models">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Generative approaches to statistical learning first seek to estimate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p(x|y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p(x|y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b99b32ed9c0b94759956558b359f8da3ab98a23f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:6.2ex; height:2.843ex;" alt="p(x|y)"/></span>,<sup class="noprint Inline-Template" style="white-space:nowrap;">&#91;<i><a href="/wiki/Wikipedia:Disputed_statement" class="mw-redirect" title="Wikipedia:Disputed statement"><span title="This claim has reliable sources with contradicting facts (November 2017)">disputed</span></a>&#32;<span class="metadata"> &#8211; <a href="/wiki/Talk:Semi-supervised_learning" title="Talk:Semi-supervised learning">discuss</a></span></i>&#93;</sup> the distribution of data points belonging to each class.  The probability <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p(y|x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p(y|x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3cad17372ea694e639c3881b2b5583632cdaa0ac" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:6.2ex; height:2.843ex;" alt="p(y|x)"/></span> that a given point <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>x</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="x"/></span> has label <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>y</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b8a6208ec717213d4317e666f1ae872e00620a0d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.155ex; height:2.009ex;" alt="y"/></span> is then proportional to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p(x|y)p(y)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p(x|y)p(y)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c143e52e1ea6009cb114283e625d14e3d6c8374" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:10.334ex; height:2.843ex;" alt="p(x|y)p(y)"/></span> by <a href="/wiki/Bayes%27_theorem" title="Bayes&#39; theorem">Bayes\' rule</a>.  Semi-supervised learning with <a href="/wiki/Generative_model" title="Generative model">generative models</a> can be viewed either as an extension of supervised learning (classification plus information about <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8cb7afced134ef75572e5314a5d278c2d644f438" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:4.398ex; height:2.843ex;" alt="p(x)"/></span>) or as an extension of unsupervised learning (clustering plus some labels).\n</p><p>Generative models assume that the distributions take some particular form <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p(x|y,\\theta )}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>y</mi>\n        <mo>,</mo>\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p(x|y,\\theta )}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/814281f66d6aa10e386cfd04488bfe0afd8f13de" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:8.325ex; height:2.843ex;" alt="p(x|y,\\theta )"/></span> parameterized by the vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\theta }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\theta }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;" alt="\\theta "/></span>.  If these assumptions are incorrect, the unlabeled data may actually decrease the accuracy of the solution relative to what would have been obtained from labeled data alone.\n<sup id="cite_ref-8" class="reference"><a href="#cite_note-8">&#91;8&#93;</a></sup>  \nHowever, if the assumptions are correct, then the unlabeled data necessarily improves performance.<sup id="cite_ref-Ratsaby_6-1" class="reference"><a href="#cite_note-Ratsaby-6">&#91;6&#93;</a></sup>\n</p><p>The unlabeled data are distributed according to a mixture of individual-class distributions.  In order to learn the mixture distribution from the unlabeled data, it must be identifiable, that is, different parameters must yield different summed distributions.  Gaussian mixture distributions are identifiable and commonly used for generative models.\n</p><p>The parameterized <a href="/wiki/Joint_distribution" class="mw-redirect" title="Joint distribution">joint distribution</a> can be written as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle p(x,y|\\theta )=p(y|\\theta )p(x|y,\\theta )}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo>,</mo>\n        <mi>y</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n        <mo stretchy="false">)</mo>\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>y</mi>\n        <mo>,</mo>\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle p(x,y|\\theta )=p(y|\\theta )p(x|y,\\theta )}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e2ac1816799d6f03d29974d31d46052577af1d76" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; margin-left: -0.089ex; width:25.53ex; height:2.843ex;" alt="p(x,y|\\theta )=p(y|\\theta )p(x|y,\\theta )"/></span> by using the <a href="/wiki/Chain_rule_(probability)" title="Chain rule (probability)">Chain rule</a>.  Each parameter vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\theta }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\theta }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e5ab2664b422d53eb0c7df3b87e1360d75ad9af" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.09ex; height:2.176ex;" alt="\\theta "/></span> is associated with a decision function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f_{\\theta }(x)={\\underset {y}{\\operatorname {argmax} }}\\ p(y|x,\\theta )}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>f</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <munder>\n            <mi>argmax</mi>\n            <mi>y</mi>\n          </munder>\n        </mrow>\n        <mtext>&#xA0;</mtext>\n        <mi>p</mi>\n        <mo stretchy="false">(</mo>\n        <mi>y</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>x</mi>\n        <mo>,</mo>\n        <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n        <mo stretchy="false">)</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f_{\\theta }(x)={\\underset {y}{\\operatorname {argmax} }}\\ p(y|x,\\theta )}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f945455e371eed97409081ee3b088dee3aa03e49" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.671ex; width:24.758ex; height:4.676ex;" alt="f_{\\theta }(x)={\\underset {y}{\\operatorname {argmax} }}\\ p(y|x,\\theta )"/></span>.  \nThe parameter is then chosen based on fit to both the labeled and unlabeled data, weighted by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\lambda }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03BB;<!-- \xce\xbb --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\lambda }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b43d0ea3c9c025af1be9128e62a18fa74bedda2a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.355ex; height:2.176ex;" alt="\\lambda "/></span>:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\underset {\\Theta }{\\operatorname {argmax} }}\\left(\\log p(\\{x_{i},y_{i}\\}_{i=1}^{l}|\\theta )+\\lambda \\log p(\\{x_{i}\\}_{i=l+1}^{l+u}|\\theta )\\right)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <munder>\n            <mi>argmax</mi>\n            <mi mathvariant="normal">&#x0398;<!-- \xce\x98 --></mi>\n          </munder>\n        </mrow>\n        <mrow>\n          <mo>(</mo>\n          <mrow>\n            <mi>log</mi>\n            <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n            <mi>p</mi>\n            <mo stretchy="false">(</mo>\n            <mo fence="false" stretchy="false">{</mo>\n            <msub>\n              <mi>x</mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n              </mrow>\n            </msub>\n            <mo>,</mo>\n            <msub>\n              <mi>y</mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n              </mrow>\n            </msub>\n            <msubsup>\n              <mo fence="false" stretchy="false">}</mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n                <mo>=</mo>\n                <mn>1</mn>\n              </mrow>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>l</mi>\n              </mrow>\n            </msubsup>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mo stretchy="false">|</mo>\n            </mrow>\n            <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n            <mo stretchy="false">)</mo>\n            <mo>+</mo>\n            <mi>&#x03BB;<!-- \xce\xbb --></mi>\n            <mi>log</mi>\n            <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n            <mi>p</mi>\n            <mo stretchy="false">(</mo>\n            <mo fence="false" stretchy="false">{</mo>\n            <msub>\n              <mi>x</mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n              </mrow>\n            </msub>\n            <msubsup>\n              <mo fence="false" stretchy="false">}</mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n                <mo>=</mo>\n                <mi>l</mi>\n                <mo>+</mo>\n                <mn>1</mn>\n              </mrow>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>l</mi>\n                <mo>+</mo>\n                <mi>u</mi>\n              </mrow>\n            </msubsup>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mo stretchy="false">|</mo>\n            </mrow>\n            <mi>&#x03B8;<!-- \xce\xb8 --></mi>\n            <mo stretchy="false">)</mo>\n          </mrow>\n          <mo>)</mo>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\underset {\\Theta }{\\operatorname {argmax} }}\\left(\\log p(\\{x_{i},y_{i}\\}_{i=1}^{l}|\\theta )+\\lambda \\log p(\\{x_{i}\\}_{i=l+1}^{l+u}|\\theta )\\right)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a7aa70fbdeafcdc211033ec8e176fa857a802f6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:50.262ex; height:4.843ex;" alt="{\\underset {\\Theta }{\\operatorname {argmax} }}\\left(\\log p(\\{x_{i},y_{i}\\}_{i=1}^{l}|\\theta )+\\lambda \\log p(\\{x_{i}\\}_{i=l+1}^{l+u}|\\theta )\\right)"/></span></dd></dl>\n<p><sup id="cite_ref-SSL_EoML_9-0" class="reference"><a href="#cite_note-SSL_EoML-9">&#91;9&#93;</a></sup>\n</p>\n<h3><span class="mw-headline" id="Low-density_separation">Low-density separation</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=8" title="Edit section: Low-density separation">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Another major class of method attempts to place boundaries in regions where there are few data points (labeled or unlabeled).  One of the most commonly used algorithms is the <a href="/wiki/Support_vector_machine#Transductive_support_vector_machines" class="mw-redirect" title="Support vector machine">transductive support vector machine</a>, or TSVM (which, despite its name, may be used for inductive learning as well).  Whereas <a href="/wiki/Support_vector_machines" class="mw-redirect" title="Support vector machines">support vector machines</a> for supervised learning seek a decision boundary with maximal <a href="/wiki/Margin_(machine_learning)" title="Margin (machine learning)">margin</a> over the labeled data, the goal of TSVM is a labeling of the unlabeled data such that the decision boundary has maximal margin over all of the data.  In addition to the standard <a href="/wiki/Hinge_loss" title="Hinge loss">hinge loss</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle (1-yf(x))_{+}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo stretchy="false">(</mo>\n        <mn>1</mn>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>y</mi>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <msub>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo>+</mo>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle (1-yf(x))_{+}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/56caba62f006f7d77e475adb6ea090fd8dc829da" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:12.896ex; height:2.843ex;" alt="(1-yf(x))_{+}"/></span> for labeled data, a loss function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle (1-|f(x)|)_{+}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo stretchy="false">(</mo>\n        <mn>1</mn>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <msub>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo>+</mo>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle (1-|f(x)|)_{+}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3c64faf68d1ad0a3c9f9ea7fcf0521491e86453d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:13.034ex; height:2.843ex;" alt="(1-|f(x)|)_{+}"/></span> is introduced over the unlabeled data by letting <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle y=\\operatorname {sign} {f(x)}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>y</mi>\n        <mo>=</mo>\n        <mi>sign</mi>\n        <mo>&#x2061;<!-- \xe2\x81\xa1 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mi>f</mi>\n          <mo stretchy="false">(</mo>\n          <mi>x</mi>\n          <mo stretchy="false">)</mo>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle y=\\operatorname {sign} {f(x)}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1b9c83b2319d29f77f9c6ffc8b4a8fd3b426bb36" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:13.077ex; height:2.843ex;" alt="y=\\operatorname {sign} {f(x)}"/></span>.  TSVM then selects <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f^{*}(x)=h^{*}(x)+b}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msup>\n          <mi>f</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo>&#x2217;<!-- \xe2\x88\x97 --></mo>\n          </mrow>\n        </msup>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>=</mo>\n        <msup>\n          <mi>h</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo>&#x2217;<!-- \xe2\x88\x97 --></mo>\n          </mrow>\n        </msup>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mo>+</mo>\n        <mi>b</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f^{*}(x)=h^{*}(x)+b}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/188cec367978923197f8da14e236e6ec925b7fc1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:17.982ex; height:2.843ex;" alt="f^{*}(x)=h^{*}(x)+b"/></span> from a <a href="/wiki/Reproducing_kernel_Hilbert_space" title="Reproducing kernel Hilbert space">reproducing kernel Hilbert space</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\mathcal {H}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;" alt="{\\mathcal {H}}"/></span> by minimizing the <a href="/wiki/Regularization_(mathematics)" title="Regularization (mathematics)">regularized</a> <a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">empirical risk</a>:\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle f^{*}={\\underset {f}{\\operatorname {argmin} }}\\left(\\displaystyle \\sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\\lambda _{1}\\|h\\|_{\\mathcal {H}}^{2}+\\lambda _{2}\\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\\right)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msup>\n          <mi>f</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo>&#x2217;<!-- \xe2\x88\x97 --></mo>\n          </mrow>\n        </msup>\n        <mo>=</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <munder>\n            <mi>argmin</mi>\n            <mi>f</mi>\n          </munder>\n        </mrow>\n        <mrow>\n          <mo>(</mo>\n          <mstyle displaystyle="true" scriptlevel="0">\n            <munderover>\n              <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n                <mo>=</mo>\n                <mn>1</mn>\n              </mrow>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>l</mi>\n              </mrow>\n            </munderover>\n            <mo stretchy="false">(</mo>\n            <mn>1</mn>\n            <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n            <msub>\n              <mi>y</mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n              </mrow>\n            </msub>\n            <mi>f</mi>\n            <mo stretchy="false">(</mo>\n            <msub>\n              <mi>x</mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n              </mrow>\n            </msub>\n            <mo stretchy="false">)</mo>\n            <msub>\n              <mo stretchy="false">)</mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mo>+</mo>\n              </mrow>\n            </msub>\n            <mo>+</mo>\n            <msub>\n              <mi>&#x03BB;<!-- \xce\xbb --></mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mn>1</mn>\n              </mrow>\n            </msub>\n            <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n            <mi>h</mi>\n            <msubsup>\n              <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n                </mrow>\n              </mrow>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mn>2</mn>\n              </mrow>\n            </msubsup>\n            <mo>+</mo>\n            <msub>\n              <mi>&#x03BB;<!-- \xce\xbb --></mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mn>2</mn>\n              </mrow>\n            </msub>\n            <munderover>\n              <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n                <mo>=</mo>\n                <mi>l</mi>\n                <mo>+</mo>\n                <mn>1</mn>\n              </mrow>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>l</mi>\n                <mo>+</mo>\n                <mi>u</mi>\n              </mrow>\n            </munderover>\n            <mo stretchy="false">(</mo>\n            <mn>1</mn>\n            <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mo stretchy="false">|</mo>\n            </mrow>\n            <mi>f</mi>\n            <mo stretchy="false">(</mo>\n            <msub>\n              <mi>x</mi>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi>i</mi>\n              </mrow>\n            </msub>\n            <mo stretchy="false">)</mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mo stretchy="false">|</mo>\n            </mrow>\n            <msub>\n              <mo stretchy="false">)</mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mo>+</mo>\n              </mrow>\n            </msub>\n          </mstyle>\n          <mo>)</mo>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle f^{*}={\\underset {f}{\\operatorname {argmin} }}\\left(\\displaystyle \\sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\\lambda _{1}\\|h\\|_{\\mathcal {H}}^{2}+\\lambda _{2}\\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\\right)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/280fd60cca5b00621dffd739326086e6d1152944" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.171ex; width:68.93ex; height:7.509ex;" alt="{\\displaystyle f^{*}={\\underset {f}{\\operatorname {argmin} }}\\left(\\displaystyle \\sum _{i=1}^{l}(1-y_{i}f(x_{i}))_{+}+\\lambda _{1}\\|h\\|_{\\mathcal {H}}^{2}+\\lambda _{2}\\sum _{i=l+1}^{l+u}(1-|f(x_{i})|)_{+}\\right)}"/></span></dd></dl>\n<p>An exact solution is intractable due to the non-<a href="/wiki/Convex_function" title="Convex function">convex</a> term <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle (1-|f(x)|)_{+}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo stretchy="false">(</mo>\n        <mn>1</mn>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <mi>x</mi>\n        <mo stretchy="false">)</mo>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mo stretchy="false">|</mo>\n        </mrow>\n        <msub>\n          <mo stretchy="false">)</mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mo>+</mo>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle (1-|f(x)|)_{+}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3c64faf68d1ad0a3c9f9ea7fcf0521491e86453d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:13.034ex; height:2.843ex;" alt="(1-|f(x)|)_{+}"/></span>, so research has focused on finding useful approximations.<sup id="cite_ref-SSL_EoML_9-1" class="reference"><a href="#cite_note-SSL_EoML-9">&#91;9&#93;</a></sup>\n</p><p>Other approaches that implement low-density separation include Gaussian process models, information regularization, and entropy minimization (of which TSVM is a special case).\n</p>\n<h3><span class="mw-headline" id="Graph-based_methods">Graph-based methods</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=9" title="Edit section: Graph-based methods">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Graph-based methods for semi-supervised learning use a graph representation of the data, with a node for each labeled and unlabeled example.  The graph may be constructed using domain knowledge or similarity of examples; two common methods are to connect each data point to its <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle k}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>k</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle k}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.211ex; height:2.176ex;" alt="k"/></span> nearest neighbors or to examples within some distance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\epsilon }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>&#x03F5;<!-- \xcf\xb5 --></mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\epsilon }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3837cad72483d97bcdde49c85d3b7b859fb3fd2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:0.944ex; height:1.676ex;" alt="\\epsilon "/></span>.  The weight <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle W_{ij}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>W</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n            <mi>j</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle W_{ij}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/29c09e9d719bb634d8ca5a6172b0562b945bf325" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:3.671ex; height:2.843ex;" alt="W_{ij}"/></span> of an edge between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{i}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{i}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="x_{i}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{j}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{j}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db47cb3d2f9496205a17a6856c91c1d3d363ccd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.239ex; height:2.343ex;" alt="x_{j}"/></span> is then set to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle e^{\\frac {-\\|x_{i}-x_{j}\\|^{2}}{\\epsilon }}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msup>\n          <mi>e</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mfrac>\n              <mrow>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n                <msub>\n                  <mi>x</mi>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mi>i</mi>\n                  </mrow>\n                </msub>\n                <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n                <msub>\n                  <mi>x</mi>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mi>j</mi>\n                  </mrow>\n                </msub>\n                <msup>\n                  <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mn>2</mn>\n                  </mrow>\n                </msup>\n              </mrow>\n              <mi>&#x03F5;<!-- \xcf\xb5 --></mi>\n            </mfrac>\n          </mrow>\n        </msup>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle e^{\\frac {-\\|x_{i}-x_{j}\\|^{2}}{\\epsilon }}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f664e52a49df1855b25aff5a35b7a6a5d0d52764" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:9.167ex; height:4.509ex;" alt="{\\displaystyle e^{\\frac {-\\|x_{i}-x_{j}\\|^{2}}{\\epsilon }}}"/></span>.\n</p><p>Within the framework of <a href="/wiki/Manifold_regularization" title="Manifold regularization">manifold regularization</a>,<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup> \n<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup>\nthe graph serves as a proxy for the manifold.  A term is added to the standard <a href="/wiki/Tikhonov_regularization" title="Tikhonov regularization">Tikhonov regularization</a> problem to enforce smoothness of the solution relative to the manifold (in the intrinsic space of the problem) as well as relative to the ambient input space.  The minimization problem becomes\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\underset {f\\in {\\mathcal {H}}}{\\operatorname {argmin} }}\\left({\\frac {1}{l}}\\displaystyle \\sum _{i=1}^{l}V(f(x_{i}),y_{i})+\\lambda _{A}\\|f\\|_{\\mathcal {H}}^{2}+\\lambda _{I}\\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)\\right)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <munder>\n            <mi>argmin</mi>\n            <mrow>\n              <mi>f</mi>\n              <mo>&#x2208;<!-- \xe2\x88\x88 --></mo>\n              <mrow class="MJX-TeXAtom-ORD">\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n                </mrow>\n              </mrow>\n            </mrow>\n          </munder>\n        </mrow>\n        <mrow>\n          <mo>(</mo>\n          <mrow>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mfrac>\n                <mn>1</mn>\n                <mi>l</mi>\n              </mfrac>\n            </mrow>\n            <mstyle displaystyle="true" scriptlevel="0">\n              <munderover>\n                <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>i</mi>\n                  <mo>=</mo>\n                  <mn>1</mn>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>l</mi>\n                </mrow>\n              </munderover>\n              <mi>V</mi>\n              <mo stretchy="false">(</mo>\n              <mi>f</mi>\n              <mo stretchy="false">(</mo>\n              <msub>\n                <mi>x</mi>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>i</mi>\n                </mrow>\n              </msub>\n              <mo stretchy="false">)</mo>\n              <mo>,</mo>\n              <msub>\n                <mi>y</mi>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>i</mi>\n                </mrow>\n              </msub>\n              <mo stretchy="false">)</mo>\n              <mo>+</mo>\n              <msub>\n                <mi>&#x03BB;<!-- \xce\xbb --></mi>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>A</mi>\n                </mrow>\n              </msub>\n              <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n              <mi>f</mi>\n              <msubsup>\n                <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n                  </mrow>\n                </mrow>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mn>2</mn>\n                </mrow>\n              </msubsup>\n              <mo>+</mo>\n              <msub>\n                <mi>&#x03BB;<!-- \xce\xbb --></mi>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mi>I</mi>\n                </mrow>\n              </msub>\n              <msub>\n                <mo>&#x222B;<!-- \xe2\x88\xab --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n                  </mrow>\n                </mrow>\n              </msub>\n              <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n              <msub>\n                <mi mathvariant="normal">&#x2207;<!-- \xe2\x88\x87 --></mi>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mrow class="MJX-TeXAtom-ORD">\n                    <mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n                  </mrow>\n                </mrow>\n              </msub>\n              <mi>f</mi>\n              <mo stretchy="false">(</mo>\n              <mi>x</mi>\n              <mo stretchy="false">)</mo>\n              <msup>\n                <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n                <mrow class="MJX-TeXAtom-ORD">\n                  <mn>2</mn>\n                </mrow>\n              </msup>\n              <mi>d</mi>\n              <mi>p</mi>\n              <mo stretchy="false">(</mo>\n              <mi>x</mi>\n              <mo stretchy="false">)</mo>\n            </mstyle>\n          </mrow>\n          <mo>)</mo>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\underset {f\\in {\\mathcal {H}}}{\\operatorname {argmin} }}\\left({\\frac {1}{l}}\\displaystyle \\sum _{i=1}^{l}V(f(x_{i}),y_{i})+\\lambda _{A}\\|f\\|_{\\mathcal {H}}^{2}+\\lambda _{I}\\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)\\right)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f33f9ab7b0ce90d7a27a4d16f934bacf1cb515f7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.171ex; width:66.97ex; height:7.509ex;" alt="{\\displaystyle {\\underset {f\\in {\\mathcal {H}}}{\\operatorname {argmin} }}\\left({\\frac {1}{l}}\\displaystyle \\sum _{i=1}^{l}V(f(x_{i}),y_{i})+\\lambda _{A}\\|f\\|_{\\mathcal {H}}^{2}+\\lambda _{I}\\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)\\right)}"/></span><sup id="cite_ref-SSL_EoML_9-2" class="reference"><a href="#cite_note-SSL_EoML-9">&#91;9&#93;</a></sup></dd></dl>\n<p>where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\mathcal {H}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi class="MJX-tex-caligraphic" mathvariant="script">H</mi>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {H}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/19ef4c7b923a5125ac91aa491838a95ee15b804f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.964ex; height:2.176ex;" alt="{\\mathcal {H}}"/></span> is a reproducing kernel Hilbert space and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle {\\mathcal {M}}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n          </mrow>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle {\\mathcal {M}}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2cc2abebd45ec020509a0ec548b67c9a2cb7cecd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.791ex; height:2.176ex;" alt="{\\mathcal {M}}"/></span> is the manifold on which the data lie.  The regularization parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\lambda _{A}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>&#x03BB;<!-- \xce\xbb --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>A</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\lambda _{A}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a3bcf5b35ccd34136b0529d005ffa35e142f2da" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.82ex; height:2.509ex;" alt="\\lambda _{A}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\lambda _{I}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>&#x03BB;<!-- \xce\xbb --></mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>I</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\lambda _{I}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dafdfbafa01e15e5f05c424bd33e41802320399f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.416ex; height:2.509ex;" alt="\\lambda _{I}"/></span> control smoothness in the ambient and intrinsic spaces respectively.  The graph is used to approximate the intrinsic regularization term.  Defining the <a href="/wiki/Laplacian_matrix" title="Laplacian matrix">graph Laplacian</a> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle L=D-W}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mi>L</mi>\n        <mo>=</mo>\n        <mi>D</mi>\n        <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n        <mi>W</mi>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle L=D-W}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/14ee07ee510ca6515e6668dca08cf5a0de2c2544" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.505ex; width:11.881ex; height:2.343ex;" alt="L=D-W"/></span> where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle D_{ii}=\\sum _{j=1}^{l+u}W_{ij}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>D</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n            <mi>i</mi>\n          </mrow>\n        </msub>\n        <mo>=</mo>\n        <munderover>\n          <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>j</mi>\n            <mo>=</mo>\n            <mn>1</mn>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n            <mo>+</mo>\n            <mi>u</mi>\n          </mrow>\n        </munderover>\n        <msub>\n          <mi>W</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>i</mi>\n            <mi>j</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle D_{ii}=\\sum _{j=1}^{l+u}W_{ij}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/aa57df37ac824bc13805e4ec8a46f813954b4414" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:13.803ex; height:7.676ex;" alt="D_{ii}=\\sum _{j=1}^{l+u}W_{ij}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\mathbf {f} }">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mrow class="MJX-TeXAtom-ORD">\n          <mi mathvariant="bold">f</mi>\n        </mrow>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\mathbf {f} }</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/dc6194e680a4e7c521f2178c50eea302843a852d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.053ex; height:2.176ex;" alt="\\mathbf {f} "/></span> the vector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle [f(x_{1})\\dots f(x_{l+u})]}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <mo stretchy="false">[</mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mi>f</mi>\n        <mo stretchy="false">(</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n            <mo>+</mo>\n            <mi>u</mi>\n          </mrow>\n        </msub>\n        <mo stretchy="false">)</mo>\n        <mo stretchy="false">]</mo>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle [f(x_{1})\\dots f(x_{l+u})]}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6fc6d44b39ef81da8df4a1be81285c9d6045154b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:17.622ex; height:2.843ex;" alt="[f(x_{1})\\dots f(x_{l+u})]"/></span>, we have\n</p>\n<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle \\mathbf {f} ^{T}L\\mathbf {f} =\\displaystyle \\sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\\approx \\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msup>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi mathvariant="bold">f</mi>\n          </mrow>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>T</mi>\n          </mrow>\n        </msup>\n        <mi>L</mi>\n        <mrow class="MJX-TeXAtom-ORD">\n          <mi mathvariant="bold">f</mi>\n        </mrow>\n        <mo>=</mo>\n        <mstyle displaystyle="true" scriptlevel="0">\n          <munderover>\n            <mo>&#x2211;<!-- \xe2\x88\x91 --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n              <mo>,</mo>\n              <mi>j</mi>\n              <mo>=</mo>\n              <mn>1</mn>\n            </mrow>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>l</mi>\n              <mo>+</mo>\n              <mi>u</mi>\n            </mrow>\n          </munderover>\n          <msub>\n            <mi>W</mi>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n              <mi>j</mi>\n            </mrow>\n          </msub>\n          <mo stretchy="false">(</mo>\n          <msub>\n            <mi>f</mi>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>i</mi>\n            </mrow>\n          </msub>\n          <mo>&#x2212;<!-- \xe2\x88\x92 --></mo>\n          <msub>\n            <mi>f</mi>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mi>j</mi>\n            </mrow>\n          </msub>\n          <msup>\n            <mo stretchy="false">)</mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mn>2</mn>\n            </mrow>\n          </msup>\n          <mo>&#x2248;<!-- \xe2\x89\x88 --></mo>\n          <msub>\n            <mo>&#x222B;<!-- \xe2\x88\xab --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n              </mrow>\n            </mrow>\n          </msub>\n          <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n          <msub>\n            <mi mathvariant="normal">&#x2207;<!-- \xe2\x88\x87 --></mi>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mrow class="MJX-TeXAtom-ORD">\n                <mi class="MJX-tex-caligraphic" mathvariant="script">M</mi>\n              </mrow>\n            </mrow>\n          </msub>\n          <mi>f</mi>\n          <mo stretchy="false">(</mo>\n          <mi>x</mi>\n          <mo stretchy="false">)</mo>\n          <msup>\n            <mo fence="false" stretchy="false">&#x2016;<!-- \xe2\x80\x96 --></mo>\n            <mrow class="MJX-TeXAtom-ORD">\n              <mn>2</mn>\n            </mrow>\n          </msup>\n          <mi>d</mi>\n          <mi>p</mi>\n          <mo stretchy="false">(</mo>\n          <mi>x</mi>\n          <mo stretchy="false">)</mo>\n        </mstyle>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle \\mathbf {f} ^{T}L\\mathbf {f} =\\displaystyle \\sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\\approx \\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4ff2e4d31e189b9d0c55afd5f39fb878d546fe63" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:50.247ex; height:7.676ex;" alt="{\\displaystyle \\mathbf {f} ^{T}L\\mathbf {f} =\\displaystyle \\sum _{i,j=1}^{l+u}W_{ij}(f_{i}-f_{j})^{2}\\approx \\int _{\\mathcal {M}}\\|\\nabla _{\\mathcal {M}}f(x)\\|^{2}dp(x)}"/></span>.</dd></dl>\n<p>The Laplacian can also be used to extend the supervised learning algorithms\xef\xbc\x9a regularized least squares and support vector machines (SVM) to semi-supervised versions Laplacian regularized least squares and Laplacian SVM.\n</p>\n<h3><span class="mw-headline" id="Heuristic_approaches">Heuristic approaches</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=10" title="Edit section: Heuristic approaches">edit</a><span class="mw-editsection-bracket">]</span></span></h3>\n<p>Some methods for semi-supervised learning are not intrinsically geared to learning from both unlabeled and labeled data, but instead make use of unlabeled data within a supervised learning framework.  For instance, the labeled and unlabeled examples <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\\displaystyle x_{1},\\dots ,x_{l+u}}">\n  <semantics>\n    <mrow class="MJX-TeXAtom-ORD">\n      <mstyle displaystyle="true" scriptlevel="0">\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mn>1</mn>\n          </mrow>\n        </msub>\n        <mo>,</mo>\n        <mo>&#x2026;<!-- \xe2\x80\xa6 --></mo>\n        <mo>,</mo>\n        <msub>\n          <mi>x</mi>\n          <mrow class="MJX-TeXAtom-ORD">\n            <mi>l</mi>\n            <mo>+</mo>\n            <mi>u</mi>\n          </mrow>\n        </msub>\n      </mstyle>\n    </mrow>\n    <annotation encoding="application/x-tex">{\\displaystyle x_{1},\\dots ,x_{l+u}}</annotation>\n  </semantics>\n</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/48fa9a910a81b5833b529973e1511c5be43ce25f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:11.833ex; height:2.009ex;" alt="x_{1},\\dots ,x_{l+u}"/></span> may inform a choice of representation, <a href="/wiki/Distance_metric" class="mw-redirect" title="Distance metric">distance metric</a>, or <a href="/w/index.php?title=Kernel(statistics)&amp;action=edit&amp;redlink=1" class="new" title="Kernel(statistics) (page does not exist)">kernel</a> for the data in an unsupervised first step.  Then supervised learning proceeds from only the labeled examples.\n</p><p><i>Self-training</i> is a wrapper method for semi-supervised learning.<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup>  First a supervised learning algorithm is trained based on the labeled data only.  This classifier is then applied to the unlabeled data to generate more labeled examples as input for the supervised learning algorithm.  Generally only the labels the classifier is most confident of are added at each step.<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup>\n</p><p><a href="/wiki/Co-training" title="Co-training">Co-training</a> is an extension of self-training in which multiple classifiers are trained on different (ideally disjoint) sets of features and generate labeled examples for one another.<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup>\n</p>\n<h2><span class="mw-headline" id="In_human_cognition">In human cognition</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=11" title="Edit section: In human cognition">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<p>Human responses to formal semi-supervised learning problems have yielded varying conclusions about the degree of influence of the unlabeled data (for a summary see<sup id="cite_ref-ZhuGoldberg_15-0" class="reference"><a href="#cite_note-ZhuGoldberg-15">&#91;15&#93;</a></sup>).  More natural learning problems may also be viewed as instances of semi-supervised learning.  Much of human <a href="/wiki/Concept_learning" title="Concept learning">concept learning</a> involves a small amount of direct instruction (e.g. parental labeling of objects during childhood) combined with large amounts of unlabeled experience (e.g. observation of objects without naming or counting them, or at least without feedback).\n</p><p>Human infants are sensitive to the structure of unlabeled natural categories such as images of dogs and cats or male and female faces.<sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;16&#93;</a></sup>  More recent work has shown that infants and children take into account not only the unlabeled examples available, but the <a href="/wiki/Sampling_(statistics)" title="Sampling (statistics)">sampling</a> process from which labeled examples arise.<sup id="cite_ref-17" class="reference"><a href="#cite_note-17">&#91;17&#93;</a></sup><sup id="cite_ref-18" class="reference"><a href="#cite_note-18">&#91;18&#93;</a></sup>\n</p>\n<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=12" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a href="/wiki/PU_learning" class="mw-redirect" title="PU learning">PU learning</a></li>\n<li><a href="/wiki/Weak_supervision" title="Weak supervision">Weak supervision</a></li></ul>\n<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=13" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<div class="reflist" style="list-style-type: decimal;">\n<div class="mw-references-wrap mw-references-columns"><ol class="references">\n<li id="cite_note-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-1">^</a></b></span> <span class="reference-text"><cite class="citation journal">"Semi-Supervised Learning Literature Survey, Page 6". 2007. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.99.9681">10.1.1.99.9681</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Semi-Supervised+Learning+Literature+Survey%2C+Page+6&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.99.9681&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">&#124;journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><style data-mw-deduplicate="TemplateStyles:r886058088">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\\"""\\"""\'""\'"}.mw-parser-output .citation .cs1-lock-free a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .citation .cs1-lock-subscription a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png")no-repeat;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}</style></span>\n</li>\n<li id="cite_note-Chapelle-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-Chapelle_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Chapelle_2-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite class="citation book">Chapelle, Olivier; Sch\xc3\xb6lkopf, Bernhard; Zien, Alexander (2006). <i>Semi-supervised learning</i>. Cambridge, Mass.: MIT Press. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-0-262-03358-9" title="Special:BookSources/978-0-262-03358-9"><bdi>978-0-262-03358-9</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Semi-supervised+learning&amp;rft.place=Cambridge%2C+Mass.&amp;rft.pub=MIT+Press&amp;rft.date=2006&amp;rft.isbn=978-0-262-03358-9&amp;rft.aulast=Chapelle&amp;rft.aufirst=Olivier&amp;rft.au=Sch%C3%B6lkopf%2C+Bernhard&amp;rft.au=Zien%2C+Alexander&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-StevensKN-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-StevensKN_3-0">^</a></b></span> <span class="reference-text">Stevens, K.N.(2000), Acoustic Phonetics, MIT Press, <link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/><a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-262-69250-3" title="Special:BookSources/0-262-69250-3">0-262-69250-3</a>, 978-0-262-69250-2</span>\n</li>\n<li id="cite_note-4"><span class="mw-cite-backlink"><b><a href="#cite_ref-4">^</a></b></span> <span class="reference-text">Scudder, H.J. <a rel="nofollow" class="external text" href="https://ieeexplore.ieee.org/abstract/document/1053799/">Probability of Error of Some Adaptive Pattern-Recognition Machines</a>. IEEE Transactions on Information Theory, 11:363\xe2\x80\x93371 (1965). Cited in Chapelle et al. 2006, page 3.</span>\n</li>\n<li id="cite_note-5"><span class="mw-cite-backlink"><b><a href="#cite_ref-5">^</a></b></span> <span class="reference-text">Vapnik, V. and Chervonenkis, A. Theory of Pattern Recognition [in Russian].  Nauka, Moscow (1974). Cited in Chapelle et al. 2006, page 3.</span>\n</li>\n<li id="cite_note-Ratsaby-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-Ratsaby_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Ratsaby_6-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text">Ratsaby, J. and Venkatesh, S. <a rel="nofollow" class="external text" href="http://www.ariel.ac.il/sites/ratsaby/Publications/PDF/colt95.pdf">Learning from a mixture of labeled and unlabeled examples with parametric side information</a>. In <i>Proceedings of the Eighth Annual Conference on Computational Learning Theory</i>, pages 412-417 (1995). Cited in Chapelle et al. 2006, page 4.</span>\n</li>\n<li id="cite_note-survey-7"><span class="mw-cite-backlink"><b><a href="#cite_ref-survey_7-0">^</a></b></span> <span class="reference-text">Zhu, Xiaojin. <a rel="nofollow" class="external text" href="http://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf">Semi-supervised learning literature survey</a>. Computer Sciences, University of Wisconsin-Madison (2008).</span>\n</li>\n<li id="cite_note-8"><span class="mw-cite-backlink"><b><a href="#cite_ref-8">^</a></b></span> <span class="reference-text">Cozman, F. and Cohen, I. Risks of semi-supervised learning: how unlabeled data can degrade performance of generative classifiers.  In: Chapelle et al. (2006).</span>\n</li>\n<li id="cite_note-SSL_EoML-9"><span class="mw-cite-backlink">^ <a href="#cite_ref-SSL_EoML_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-SSL_EoML_9-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-SSL_EoML_9-2"><sup><i><b>c</b></i></sup></a></span> <span class="reference-text">Zhu, Xiaojin. <a rel="nofollow" class="external text" href="http://pages.cs.wisc.edu/~jerryzhu/pub/SSL_EoML.pdf">Semi-Supervised Learning</a> University of Wisconsin-Madison.</span>\n</li>\n<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation journal">M. Belkin; P. Niyogi (2004). <a rel="nofollow" class="external text" href="http://booksc.org/dl/11288633/421f61">"Semi-supervised Learning on Riemannian Manifolds"</a>. <i>Machine Learning</i>. <b>56</b> (Special Issue on Clustering): 209\xe2\x80\x93239. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1023%2Fb%3Amach.0000033120.25363.1e">10.1023/b:mach.0000033120.25363.1e</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Semi-supervised+Learning+on+Riemannian+Manifolds&amp;rft.volume=56&amp;rft.issue=Special+Issue+on+Clustering&amp;rft.pages=209-239&amp;rft.date=2004&amp;rft_id=info%3Adoi%2F10.1023%2Fb%3Amach.0000033120.25363.1e&amp;rft.au=M.+Belkin&amp;rft.au=P.+Niyogi&amp;rft_id=http%3A%2F%2Fbooksc.org%2Fdl%2F11288633%2F421f61&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-11"><span class="mw-cite-backlink"><b><a href="#cite_ref-11">^</a></b></span> <span class="reference-text">M. Belkin, P. Niyogi, V. Sindhwani. On Manifold Regularization. AISTATS 2005.</span>\n</li>\n<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><cite class="citation journal">Triguero, Isaac; Garc\xc3\xada, Salvador; Herrera, Francisco (2013-11-26). "Self-labeled techniques for semi-supervised learning: taxonomy, software and empirical study". <i>Knowledge and Information Systems</i>. <b>42</b> (2): 245\xe2\x80\x93284. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1007%2Fs10115-013-0706-y">10.1007/s10115-013-0706-y</a>. <a href="/wiki/International_Standard_Serial_Number" title="International Standard Serial Number">ISSN</a>&#160;<a rel="nofollow" class="external text" href="//www.worldcat.org/issn/0219-1377">0219-1377</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Knowledge+and+Information+Systems&amp;rft.atitle=Self-labeled+techniques+for+semi-supervised+learning%3A+taxonomy%2C+software+and+empirical+study&amp;rft.volume=42&amp;rft.issue=2&amp;rft.pages=245-284&amp;rft.date=2013-11-26&amp;rft_id=info%3Adoi%2F10.1007%2Fs10115-013-0706-y&amp;rft.issn=0219-1377&amp;rft.aulast=Triguero&amp;rft.aufirst=Isaac&amp;rft.au=Garc%C3%ADa%2C+Salvador&amp;rft.au=Herrera%2C+Francisco&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-13">^</a></b></span> <span class="reference-text"><cite class="citation journal">Fazakis, Nikos; Karlos, Stamatis; Kotsiantis, Sotiris; Sgarbas, Kyriakos (2015-12-29). <a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4709606">"Self-Trained LMT for Semisupervised Learning"</a>. <i>Computational Intelligence and Neuroscience</i>. <b>2016</b>: 3057481. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1155%2F2016%2F3057481">10.1155/2016/3057481</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4709606">4709606</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/26839531">26839531</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computational+Intelligence+and+Neuroscience&amp;rft.atitle=Self-Trained+LMT+for+Semisupervised+Learning&amp;rft.volume=2016&amp;rft.pages=3057481&amp;rft.date=2015-12-29&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4709606&amp;rft_id=info%3Apmid%2F26839531&amp;rft_id=info%3Adoi%2F10.1155%2F2016%2F3057481&amp;rft.aulast=Fazakis&amp;rft.aufirst=Nikos&amp;rft.au=Karlos%2C+Stamatis&amp;rft.au=Kotsiantis%2C+Sotiris&amp;rft.au=Sgarbas%2C+Kyriakos&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4709606&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-14">^</a></b></span> <span class="reference-text"><cite class="citation book">Didaci, Luca; Fumera, Giorgio; Roli, Fabio (2012-11-07).  Gimel\xe2\x80\x99farb, Georgy; Hancock, Edwin; Imiya, Atsushi; Kuijper, Arjan; Kudo, Mineichi; Omachi, Shinichiro; Windeatt, Terry; Yamada, Keiji (eds.). <i>Analysis of Co-training Algorithm with Very Small Training Sets</i>. Lecture Notes in Computer Science. Springer Berlin Heidelberg. pp.&#160;719\xe2\x80\x93726. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1007%2F978-3-642-34166-3_79">10.1007/978-3-642-34166-3_79</a>. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9783642341656" title="Special:BookSources/9783642341656"><bdi>9783642341656</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Analysis+of+Co-training+Algorithm+with+Very+Small+Training+Sets&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=719-726&amp;rft.pub=Springer+Berlin+Heidelberg&amp;rft.date=2012-11-07&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-642-34166-3_79&amp;rft.isbn=9783642341656&amp;rft.aulast=Didaci&amp;rft.aufirst=Luca&amp;rft.au=Fumera%2C+Giorgio&amp;rft.au=Roli%2C+Fabio&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-ZhuGoldberg-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-ZhuGoldberg_15-0">^</a></b></span> <span class="reference-text">\n<cite class="citation book">Zhu, Xiaojin; Goldberg, Andrew B. (2009). <i>Introduction to semi-supervised learning</i>. Morgan &amp; Claypool. <a href="/wiki/International_Standard_Book_Number" title="International Standard Book Number">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9781598295481" title="Special:BookSources/9781598295481"><bdi>9781598295481</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+semi-supervised+learning.&amp;rft.pub=Morgan+%26+Claypool&amp;rft.date=2009&amp;rft.isbn=9781598295481&amp;rft.aulast=Zhu&amp;rft.aufirst=Xiaojin&amp;rft.au=Goldberg%2C+Andrew+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite class="citation journal">Younger B. A.; Fearing D. D. (1999). "Parsing Items into Separate Categories: Developmental Change in Infant Categorization". <i>Child Development</i>. <b>70</b> (2): 291\xe2\x80\x93303. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1111%2F1467-8624.00022">10.1111/1467-8624.00022</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Child+Development&amp;rft.atitle=Parsing+Items+into+Separate+Categories%3A+Developmental+Change+in+Infant+Categorization&amp;rft.volume=70&amp;rft.issue=2&amp;rft.pages=291-303&amp;rft.date=1999&amp;rft_id=info%3Adoi%2F10.1111%2F1467-8624.00022&amp;rft.au=Younger+B.+A.&amp;rft.au=Fearing+D.+D.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite class="citation journal">Xu, F. &amp; Tenenbaum, J. B. (2007). "Sensitivity to sampling in Bayesian word learning. Developmental Science". <i>Developmental Science</i>. <b>10</b> (3): 288\xe2\x80\x93297. <a href="/wiki/CiteSeerX" title="CiteSeerX">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.7505">10.1.1.141.7505</a></span>. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1111%2Fj.1467-7687.2007.00590.x">10.1111/j.1467-7687.2007.00590.x</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Developmental+Science&amp;rft.atitle=Sensitivity+to+sampling+in+Bayesian+word+learning.+Developmental+Science&amp;rft.volume=10&amp;rft.issue=3&amp;rft.pages=288-297&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.141.7505&amp;rft_id=info%3Adoi%2F10.1111%2Fj.1467-7687.2007.00590.x&amp;rft.au=Xu%2C+F.&amp;rft.au=Tenenbaum%2C+J.+B.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite class="citation journal">Gweon, H., Tenenbaum J.B., and Schulz L.E (2010). <a rel="nofollow" class="external text" href="http://www.pnas.org/content/107/20/9066">"Infants consider both the sample and the sampling process in inductive generalization"</a>. <i>Proc Natl Acad Sci U S A</i>. <b>107</b> (20): 9066\xe2\x80\x9371. <a href="/wiki/Digital_object_identifier" title="Digital object identifier">doi</a>:<a rel="nofollow" class="external text" href="//doi.org/10.1073%2Fpnas.1003095107">10.1073/pnas.1003095107</a>. <a href="/wiki/PubMed_Central" title="PubMed Central">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC2889113">2889113</a></span>. <a href="/wiki/PubMed_Identifier" class="mw-redirect" title="PubMed Identifier">PMID</a>&#160;<a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pubmed/20435914">20435914</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proc+Natl+Acad+Sci+U+S+A&amp;rft.atitle=Infants+consider+both+the+sample+and+the+sampling+process+in+inductive+generalization&amp;rft.volume=107&amp;rft.issue=20&amp;rft.pages=9066-71&amp;rft.date=2010&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC2889113&amp;rft_id=info%3Apmid%2F20435914&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.1003095107&amp;rft.au=Gweon%2C+H.%2C+Tenenbaum+J.B.%2C+and+Schulz+L.E&amp;rft_id=http%3A%2F%2Fwww.pnas.org%2Fcontent%2F107%2F20%2F9066&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASemi-supervised+learning" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: multiple names: authors list (<a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r886058088"/></span>\n</li>\n</ol></div></div>\n<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit&amp;section=14" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>\n<ul><li><a rel="nofollow" class="external autonumber" href="http://manifold.cs.uchicago.edu/manifold_regularization/software.html">[1]</a> A freely available <a href="/wiki/MATLAB" title="MATLAB">MATLAB</a> implementation of the graph-based semi-supervised algorithms Laplacian support vector machines and Laplacian regularized least squares.</li>\n<li><a rel="nofollow" class="external autonumber" href="http://sci2s.ugr.es/keel/algorithms.php#sub10">[2]</a> KEEL module for semi-supervised learning.</li>\n<li><a rel="nofollow" class="external autonumber" href="http://pages.cs.wisc.edu/~jerryzhu/ssl/software.html">[3]</a> Semi-Supervised Learning Software</li>\n<li><a rel="nofollow" class="external autonumber" href="http://scikit-learn.org/stable/modules/label_propagation.html">[4]</a> Semi-Supervised algorithms in scikit-learn  .</li></ul>\n<!-- \nNewPP limit report\nParsed by mw1247\nCached time: 20191107015842\nCache expiry: 2592000\nDynamic content: false\nComplications: [vary\xe2\x80\x90revision\xe2\x80\x90sha1]\nCPU time usage: 0.396 seconds\nReal time usage: 0.630 seconds\nPreprocessor visited node count: 1425/1000000\nPreprocessor generated node count: 0/1500000\nPost\xe2\x80\x90expand include size: 49746/2097152 bytes\nTemplate argument size: 1759/2097152 bytes\nHighest expansion depth: 15/40\nExpensive parser function count: 5/500\nUnstrip recursion depth: 1/20\nUnstrip post\xe2\x80\x90expand size: 40352/5000000 bytes\nNumber of Wikibase entities loaded: 4/400\nLua time usage: 0.169/10.000 seconds\nLua memory usage: 4.47 MB/50 MB\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  414.239      1 -total\n 67.83%  280.995      1 Template:Reflist\n 45.33%  187.789      7 Template:Cite_journal\n 13.14%   54.441      1 Template:Machine_learning_bar\n 13.06%   54.100      1 Template:Disputed_inline\n 12.02%   49.805      1 Template:Sidebar_with_collapsible_lists\n 11.29%   46.748      1 Template:Fix\n  9.46%   39.172      1 Template:ISBN\n  6.58%   27.241      1 Template:Category_handler\n  5.24%   21.687      3 Template:Cite_book\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:2829632-0!canonical!math=5 and timestamp 20191107015842 and revision id 922225491\n -->\n</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>\n\t\t\n\t\t<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;oldid=922225491">https://en.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;oldid=922225491</a>"</div>\n\t\t\n\t\t<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">CS1 maint: multiple names: authors list</a></li><li><a href="/wiki/Category:All_accuracy_disputes" title="Category:All accuracy disputes">All accuracy disputes</a></li><li><a href="/wiki/Category:Articles_with_disputed_statements_from_November_2017" title="Category:Articles with disputed statements from November 2017">Articles with disputed statements from November 2017</a></li></ul></div></div>\n\t\t<div class="visualClear"></div>\n\t\t\n\t</div>\n</div>\n<div id=\'mw-data-after-content\'>\n\t<div class="read-more-container"></div>\n</div>\n\n\n\t\t<div id="mw-navigation">\n\t\t\t<h2>Navigation menu</h2>\n\t\t\t<div id="mw-head">\n\t\t\t\t\t\t\t\t\t<div id="p-personal" role="navigation" aria-labelledby="p-personal-label">\n\t\t\t\t\t\t<h3 id="p-personal-label">Personal tools</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Semi-supervised+learning" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Semi-supervised+learning" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t<div id="left-navigation">\n\t\t\t\t\t\t\t\t\t\t<div id="p-namespaces" role="navigation" class="vectorTabs" aria-labelledby="p-namespaces-label">\n\t\t\t\t\t\t<h3 id="p-namespaces-label">Namespaces</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="ca-nstab-main" class="selected"><a href="/wiki/Semi-supervised_learning" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Semi-supervised_learning" rel="discussion" title="Discussion about the content page [t]" accesskey="t">Talk</a></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-variants" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-variants-label">\n\t\t\t\t\t\t\t\t\t\t\t\t<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-variants-label" />\n\t\t\t\t\t\t<h3 id="p-variants-label">\n\t\t\t\t\t\t\t<span>Variants</span>\n\t\t\t\t\t\t</h3>\n\t\t\t\t\t\t<ul class="menu">\n\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t<div id="right-navigation">\n\t\t\t\t\t\t\t\t\t\t<div id="p-views" role="navigation" class="vectorTabs" aria-labelledby="p-views-label">\n\t\t\t\t\t\t<h3 id="p-views-label">Views</h3>\n\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t<li id="ca-view" class="collapsible selected"><a href="/wiki/Semi-supervised_learning">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Semi-supervised_learning&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Semi-supervised_learning&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li>\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-cactions" role="navigation" class="vectorMenu emptyPortlet" aria-labelledby="p-cactions-label">\n\t\t\t\t\t\t<input type="checkbox" class="vectorMenuCheckbox" aria-labelledby="p-cactions-label" />\n\t\t\t\t\t\t<h3 id="p-cactions-label"><span>More</span></h3>\n\t\t\t\t\t\t<ul class="menu">\n\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<div id="p-search" role="search">\n\t\t\t\t\t\t<h3>\n\t\t\t\t\t\t\t<label for="searchInput">Search</label>\n\t\t\t\t\t\t</h3>\n\t\t\t\t\t\t<form action="/w/index.php" id="searchform">\n\t\t\t\t\t\t\t<div id="simpleSearch">\n\t\t\t\t\t\t\t\t<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/><input type="hidden" value="Special:Search" name="title"/><input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/><input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</form>\n\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t<div id="mw-panel">\n\t\t\t\t<div id="p-logo" role="banner"><a class="mw-wiki-logo" href="/wiki/Main_Page" title="Visit the main page"></a></div>\n\t\t\t\t\t\t<div class="portal" role="navigation" id="p-navigation" aria-labelledby="p-navigation-label">\n\t\t\t<h3 id="p-navigation-label">Navigation</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Portal:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-featuredcontent"><a href="/wiki/Portal:Featured_content" title="Featured content \xe2\x80\x93 the best of Wikipedia">Featured content</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Load a random article [x]" accesskey="x">Random article</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us">Donate to Wikipedia</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-interaction" aria-labelledby="p-interaction-label">\n\t\t\t<h3 id="p-interaction-label">Interaction</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Find out about Wikipedia">About Wikipedia</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes in the wiki [r]" accesskey="r">Recent changes</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact page</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-tb" aria-labelledby="p-tb-label">\n\t\t\t<h3 id="p-tb-label">Tools</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Semi-supervised_learning" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Semi-supervised_learning" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Semi-supervised_learning&amp;oldid=922225491" title="Permanent link to this revision of the page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Semi-supervised_learning&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q1041418" title="Link to connected data repository item [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Semi-supervised_learning&amp;id=922225491" title="Information on how to cite this page">Cite this page</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-coll-print_export" aria-labelledby="p-coll-print_export-label">\n\t\t\t<h3 id="p-coll-print_export-label">Print/export</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li id="coll-create_a_book"><a href="/w/index.php?title=Special:Book&amp;bookcmd=book_creator&amp;referer=Semi-supervised+learning">Create a book</a></li><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Semi-supervised+learning&amp;action=show-download-screen">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Semi-supervised_learning&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li>\t\t\t\t</ul>\n\t\t\t\t\t\t\t</div>\n\t\t</div>\n\t\t\t<div class="portal" role="navigation" id="p-lang" aria-labelledby="p-lang-label">\n\t\t\t<h3 id="p-lang-label">Languages</h3>\n\t\t\t<div class="body">\n\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t<li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Aprendizaje_semisupervisado" title="Aprendizaje semisupervisado \xe2\x80\x93 Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Espa\xc3\xb1ol</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%DB%8C%D8%A7%D8%AF%DA%AF%DB%8C%D8%B1%DB%8C_%D9%86%DB%8C%D9%85%D9%87%E2%80%8C%D9%86%D8%B8%D8%A7%D8%B1%D8%AA%DB%8C" title="\xdb\x8c\xd8\xa7\xd8\xaf\xda\xaf\xdb\x8c\xd8\xb1\xdb\x8c \xd9\x86\xdb\x8c\xd9\x85\xd9\x87\xe2\x80\x8c\xd9\x86\xd8\xb8\xd8\xa7\xd8\xb1\xd8\xaa\xdb\x8c \xe2\x80\x93 Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">\xd9\x81\xd8\xa7\xd8\xb1\xd8\xb3\xdb\x8c</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Apprentissage_semi-supervis%C3%A9" title="Apprentissage semi-supervis\xc3\xa9 \xe2\x80\x93 French" lang="fr" hreflang="fr" class="interlanguage-link-target">Fran\xc3\xa7ais</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EC%A4%80_%EC%A7%80%EB%8F%84_%ED%95%99%EC%8A%B5" title="\xec\xa4\x80 \xec\xa7\x80\xeb\x8f\x84 \xed\x95\x99\xec\x8a\xb5 \xe2\x80\x93 Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">\xed\x95\x9c\xea\xb5\xad\xec\x96\xb4</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5_%D1%81_%D1%87%D0%B0%D1%81%D1%82%D0%B8%D1%87%D0%BD%D1%8B%D0%BC_%D0%BF%D1%80%D0%B8%D0%B2%D0%BB%D0%B5%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%D0%BC_%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F" title="\xd0\x9e\xd0\xb1\xd1\x83\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5 \xd1\x81 \xd1\x87\xd0\xb0\xd1\x81\xd1\x82\xd0\xb8\xd1\x87\xd0\xbd\xd1\x8b\xd0\xbc \xd0\xbf\xd1\x80\xd0\xb8\xd0\xb2\xd0\xbb\xd0\xb5\xd1\x87\xd0\xb5\xd0\xbd\xd0\xb8\xd0\xb5\xd0\xbc \xd1\x83\xd1\x87\xd0\xb8\xd1\x82\xd0\xb5\xd0\xbb\xd1\x8f \xe2\x80\x93 Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">\xd0\xa0\xd1\x83\xd1\x81\xd1\x81\xd0\xba\xd0\xb8\xd0\xb9</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%9D%D0%B0%D0%BF%D1%96%D0%B2%D0%B0%D0%B2%D1%82%D0%BE%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%BD%D0%B5_%D0%BD%D0%B0%D0%B2%D1%87%D0%B0%D0%BD%D0%BD%D1%8F" title="\xd0\x9d\xd0\xb0\xd0\xbf\xd1\x96\xd0\xb2\xd0\xb0\xd0\xb2\xd1\x82\xd0\xbe\xd0\xbc\xd0\xb0\xd1\x82\xd0\xb8\xd1\x87\xd0\xbd\xd0\xb5 \xd0\xbd\xd0\xb0\xd0\xb2\xd1\x87\xd0\xb0\xd0\xbd\xd0\xbd\xd1\x8f \xe2\x80\x93 Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">\xd0\xa3\xd0\xba\xd1\x80\xd0\xb0\xd1\x97\xd0\xbd\xd1\x81\xd1\x8c\xd0\xba\xd0\xb0</a></li><li class="interlanguage-link interwiki-vi"><a href="https://vi.wikipedia.org/wiki/H%E1%BB%8Dc_n%E1%BB%ADa_gi%C3%A1m_s%C3%A1t" title="H\xe1\xbb\x8dc n\xe1\xbb\xada gi\xc3\xa1m s\xc3\xa1t \xe2\x80\x93 Vietnamese" lang="vi" hreflang="vi" class="interlanguage-link-target">Ti\xe1\xba\xbfng Vi\xe1\xbb\x87t</a></li>\t\t\t\t</ul>\n\t\t\t\t<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q1041418#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>\t\t\t</div>\n\t\t</div>\n\t\t\t\t</div>\n\t\t</div>\n\t\t\t\t<div id="footer" role="contentinfo">\n\t\t\t\t\t\t<ul id="footer-info">\n\t\t\t\t\t\t\t\t<li id="footer-info-lastmod"> This page was last edited on 20 October 2019, at 19:55<span class="anonymous-show">&#160;(UTC)</span>.</li>\n\t\t\t\t\t\t\t\t<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;\nadditional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia\xc2\xae is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t<ul id="footer-places">\n\t\t\t\t\t\t\t\t<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>\n\t\t\t\t\t\t\t\t<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Semi-supervised_learning&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>\n\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t\t\t\t\t<ul id="footer-icons" class="noprint">\n\t\t\t\t\t\t\t\t\t\t<li id="footer-copyrightico">\n\t\t\t\t\t\t<a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation"/></a>\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t<li id="footer-poweredbyico">\n\t\t\t\t\t\t<a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31"/></a>\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t<div style="clear: both;"></div>\n\t\t</div>\n\t\t\n\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.396","walltime":"0.630","ppvisitednodes":{"value":1425,"limit":1000000},"ppgeneratednodes":{"value":0,"limit":1500000},"postexpandincludesize":{"value":49746,"limit":2097152},"templateargumentsize":{"value":1759,"limit":2097152},"expansiondepth":{"value":15,"limit":40},"expensivefunctioncount":{"value":5,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":40352,"limit":5000000},"entityaccesscount":{"value":4,"limit":400},"timingprofile":["100.00%  414.239      1 -total"," 67.83%  280.995      1 Template:Reflist"," 45.33%  187.789      7 Template:Cite_journal"," 13.14%   54.441      1 Template:Machine_learning_bar"," 13.06%   54.100      1 Template:Disputed_inline"," 12.02%   49.805      1 Template:Sidebar_with_collapsible_lists"," 11.29%   46.748      1 Template:Fix","  9.46%   39.172      1 Template:ISBN","  6.58%   27.241      1 Template:Category_handler","  5.24%   21.687      3 Template:Cite_book"]},"scribunto":{"limitreport-timeusage":{"value":"0.169","limit":"10.000"},"limitreport-memusage":{"value":4691197,"limit":52428800}},"cachereport":{"origin":"mw1247","timestamp":"20191107015842","ttl":2592000,"transientcontent":false}}});});</script>\n<script type="application/ld+json">{"@context":"https:\\/\\/schema.org","@type":"Article","name":"Semi-supervised learning","url":"https:\\/\\/en.wikipedia.org\\/wiki\\/Semi-supervised_learning","sameAs":"http:\\/\\/www.wikidata.org\\/entity\\/Q1041418","mainEntity":"http:\\/\\/www.wikidata.org\\/entity\\/Q1041418","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png"}},"datePublished":"2005-10-04T04:19:02Z","dateModified":"2019-10-20T19:55:35Z","image":"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/d\\/d0\\/Example_of_unlabeled_data_in_semisupervised_learning.png","headline":"class of machine learning techniques"}</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":789,"wgHostname":"mw1247"});});</script>\n</body>\n</html>\n'