{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: Promotions\n",
    "\n",
    "In this challenge, you'll develop codes to parse and analyze data returned from another API on Zalando such as [Promos homme (Men's Promotions)\n",
    "](https://www.zalando.fr/promo-homme/) or [Promos femme (Women's Promotions)](https://www.zalando.fr/promo-femme/). The workflow is almost the same as in the guided lesson but you'll work with different data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the link\n",
    "\n",
    "Wrote your codes in the cell below to obtain the data from the API endpoint you choose. A recap of the workflow:\n",
    "\n",
    "1. Examine the webpages and choose one that you want to work with.\n",
    "\n",
    "1. Use Google Chrome's DevTools to inspect the XHR network requests. Find out the API endpoint that serves data to the webpage.\n",
    "\n",
    "1. Test the API endpoint in the browser to verify its data.\n",
    "\n",
    "1. Change the page number offset of the API URL to test if it's working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='https://www.zalando.fr/api/catalog/articles?categories=promo-homme&limit=84&offset=84&sort=sale'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "In the next cell, use Python to obtain data from the API endpoint you chose in the previous step. Workflow:\n",
    "\n",
    "1. Import libraries.\n",
    "\n",
    "1. Define the initial API endpoint URL.\n",
    "\n",
    "1. Make request to obtain data of the 1st page. Flatten the data and store it in an empty object variable.\n",
    "\n",
    "1. Find out the total page count in the 1st page data.\n",
    "\n",
    "1. Use a FOR loop to make requests for the additional pages from 2 to page count. Append the data of each additional page to the flatterned data object.\n",
    "\n",
    "1. Print and review the data you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.status_code\n",
    "\n",
    "results = response.json()\n",
    "results\n",
    "\n",
    "\n",
    "flattened_data = json_normalize(results)\n",
    "\n",
    "flattened_data1 = json_normalize(flattened_data.articles[0])\n",
    "flattened_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the total number of pages\n",
    "total_pages=results['pagination']['page_count']\n",
    "\n",
    "#cambiamos el offset a 168 para situarnos en la hoja2, ya que cada hoja consta de 84 productos\n",
    "\n",
    "# Your code\n",
    "df=pd.DataFrame()\n",
    "for i in range(total_pages):\n",
    "    k=84*i\n",
    "    url=f'https://www.zalando.fr/api/catalog/articles?categories=promo-homme&limit=84&offset=168&sort=sale'\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    results = response.json()\n",
    "    flattened_data = json_normalize(results)\n",
    "    flattened_data1 = json_normalize(flattened_data.articles[0])\n",
    "    flattened_data1=flattened_data1.set_index('sku')\n",
    "    df = df.append(flattened_data1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "Extract the following information from the data:\n",
    "\n",
    "* The trending brand.\n",
    "\n",
    "* The product(s) with the highest discount.\n",
    "\n",
    "* The sum of discounts of all goods (sum_discounted_prices divided by sum_original_prices)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trending brand\n",
    "df['brand_name'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vemos como vienen los datos de las columnas\n",
    "set(df['price.original'])\n",
    "set(df['price.promotional'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extraemos los valores que nos interesan y quitamos la basura\n",
    "df['price.original']=df['price.original'].str.extract('(\\d*,\\d*)')\n",
    "df['price.promotional']=df['price.promotional'].str.extract('(\\d*,\\d*)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convertimos a tipo string para poder aplicar el replace del ',' al '.'\n",
    "df['price.promotional'] = df['price.promotional'].astype(str)\n",
    "df['price.promotional'] = [x.replace(',', '.') for x in df['price.promotional']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['price.original'] = df['price.original'].astype(str)\n",
    "df['price.original'] = [x.replace(',', '.') for x in df['price.original']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convertimos a float\n",
    "df['price.promotional'] = df['price.promotional'].astype(float)\n",
    "df['price.original'] = df['price.original'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# restamos el precio d descuento al original para ver cuanto es el cobro real.\n",
    "df['descuento_real'] = df['price.original'] - df['price.promotional']\n",
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# agrupamos el data frame por la marca y se hace la suma de todos las marcas para ver cual es la que hizo los mayores descuento, y hacemos los acomodamos de mayor a menor para poder tomar el primer valor. \n",
    "dec_total=df1.groupby(['brand_name']).sum().descuento_real\n",
    "dec_total.sort_values(ascending=False).index[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Filtramos por el valor si este fue de cero, entonces no dio descuentos\n",
    "dec_total[dec_total==0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
